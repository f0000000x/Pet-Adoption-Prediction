{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd \n",
    "from numpy import array\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report, confusion_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Type</th>\n",
       "      <th>Breed1</th>\n",
       "      <th>Breed2</th>\n",
       "      <th>Gender</th>\n",
       "      <th>Color1</th>\n",
       "      <th>Color2</th>\n",
       "      <th>Color3</th>\n",
       "      <th>MaturitySize</th>\n",
       "      <th>FurLength</th>\n",
       "      <th>Vaccinated</th>\n",
       "      <th>Dewormed</th>\n",
       "      <th>Sterilized</th>\n",
       "      <th>Health</th>\n",
       "      <th>Quantity</th>\n",
       "      <th>VideoAmt</th>\n",
       "      <th>PhotoAmt</th>\n",
       "      <th>AdoptionSpeed</th>\n",
       "      <th>AgeBins</th>\n",
       "      <th>Pure_breed</th>\n",
       "      <th>Free_or_NeedFee</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>167</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>136</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>175</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>7</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>175</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>8</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>175</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>14987</td>\n",
       "      <td>1</td>\n",
       "      <td>89</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>14988</td>\n",
       "      <td>0</td>\n",
       "      <td>137</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>14989</td>\n",
       "      <td>0</td>\n",
       "      <td>136</td>\n",
       "      <td>100</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>14990</td>\n",
       "      <td>0</td>\n",
       "      <td>136</td>\n",
       "      <td>102</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>14991</td>\n",
       "      <td>0</td>\n",
       "      <td>137</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>14617 rows Ã— 20 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       Type  Breed1  Breed2  Gender  Color1  Color2  Color3  MaturitySize  \\\n",
       "0         0     167       0       1       0       6       0             3   \n",
       "1         0     136       0       1       0       1       0             2   \n",
       "2         1     175       0       1       1       6       0             2   \n",
       "3         1     175       0       0       0       1       0             2   \n",
       "4         1     175       0       1       0       0       0             2   \n",
       "...     ...     ...     ...     ...     ...     ...     ...           ...   \n",
       "14987     1      89       0       0       0       6       0             3   \n",
       "14988     0     137       0       2       0       0       0             2   \n",
       "14989     0     136     100       2       0       3       5             2   \n",
       "14990     0     136     102       2       4       5       5             1   \n",
       "14991     0     137       0       0       3       6       0             3   \n",
       "\n",
       "       FurLength  Vaccinated  Dewormed  Sterilized  Health  Quantity  \\\n",
       "0              2           0         0           0       0         0   \n",
       "1              1           1         1           1       0         0   \n",
       "2              1           2         2           0       0         0   \n",
       "3              2           2         2           0       0         0   \n",
       "4              2           0         0           0       0         0   \n",
       "...          ...         ...       ...         ...     ...       ...   \n",
       "14987          0           2         2           0       0         0   \n",
       "14988          1           0         0           0       0         3   \n",
       "14989          1           2         2           2       0         1   \n",
       "14990          1           0         2           1       0         4   \n",
       "14991          2           2         2           2       0         0   \n",
       "\n",
       "       VideoAmt  PhotoAmt  AdoptionSpeed  AgeBins  Pure_breed  Free_or_NeedFee  \n",
       "0             0         1              2        0           1                1  \n",
       "1             0         2              4        0           1                0  \n",
       "2             0         7              1        0           1                0  \n",
       "3             0         8              2        0           1                1  \n",
       "4             0         3              2        0           1                0  \n",
       "...         ...       ...            ...      ...         ...              ...  \n",
       "14987         0         1              4        1           1                0  \n",
       "14988         0         3              2        0           1                0  \n",
       "14989         0         3              3        4           0                0  \n",
       "14990         0         5              1        0           0                1  \n",
       "14991         0         3              3        1           1                0  \n",
       "\n",
       "[14617 rows x 20 columns]"
      ]
     },
     "execution_count": 152,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.read_csv('/Users/Fox/Desktop/Data Science/Capstone/Codes/EDA-Siqi/EDA.csv', index_col=0)\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame(data) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop Breed1 Breed2\n",
    "X = df[['Type', 'Gender', 'Color1', 'Color2', 'Color3', 'MaturitySize',\n",
    "       'FurLength', 'Vaccinated', 'Dewormed', 'Sterilized', 'Health',\n",
    "       'Quantity', 'VideoAmt', 'PhotoAmt', 'AgeBins',\n",
    "       'Pure_breed', 'Free_or_NeedFee']].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = np.array(df['AdoptionSpeed'].tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training set score: 0.415633\n",
      "Test set score: 0.401847\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/Fox/opt/anaconda3/lib/python3.7/site-packages/sklearn/neural_network/_multilayer_perceptron.py:470: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n"
     ]
    }
   ],
   "source": [
    "clf = MLPClassifier(solver='lbfgs', alpha=1e-5,\n",
    "                    hidden_layer_sizes=(50, 20), random_state=1)\n",
    "clf.fit(X, y)\n",
    "print(\"Training set score: %f\" % clf.score(X_train, y_train))\n",
    "print(\"Test set score: %f\" % clf.score(X_test, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = clf.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.36      0.31      0.33       578\n",
      "           1       0.42      0.17      0.24       652\n",
      "           2       0.36      0.43      0.39       804\n",
      "           3       0.45      0.66      0.54       817\n",
      "           4       0.00      0.00      0.00        73\n",
      "\n",
      "    accuracy                           0.40      2924\n",
      "   macro avg       0.32      0.31      0.30      2924\n",
      "weighted avg       0.39      0.40      0.38      2924\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/Fox/opt/anaconda3/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1272: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "weights between input and first hidden layer:\n",
      "[[-1.08015821e-02  7.60939629e-02 -2.74812158e-01 -4.03899267e-02\n",
      "  -2.25551893e-01 -1.23897956e-01 -4.83062628e-01  7.44893939e-02\n",
      "  -1.83015019e-01 -5.92348608e-02  6.48037511e-02  2.37420628e-01\n",
      "  -1.65182474e-01 -2.25345285e-02 -2.96299395e-01 -3.41764796e-02\n",
      "   1.49980801e-01 -1.94909724e-01 -4.04743416e-01 -4.95298480e-02\n",
      "   2.02188191e-01  4.08423742e-01 -2.96697299e-01  4.44648798e-01\n",
      "   5.47234745e-01 -1.82825067e-02 -2.27539398e-01 -2.73363042e-01\n",
      "  -3.91495611e-01  4.75397133e-01 -3.30978675e-01 -9.23722502e-02\n",
      "   4.98911278e-01  3.15934545e-01  2.90047292e-01 -5.76029196e-01\n",
      "   1.55213853e-01  5.53642620e-01 -1.98663324e-01 -3.48564802e-02\n",
      "   3.40983638e-01  1.19544575e-01 -9.87430589e-02  1.33974634e-01\n",
      "  -3.67659357e-01  3.19687664e-01  3.59921727e-01  1.83865236e-01\n",
      "  -2.04667815e-01 -3.81473596e-01]\n",
      " [-4.27717340e-01 -8.13093986e-02 -2.43052032e-01 -3.87330905e-01\n",
      "   7.85643899e-02 -6.46360814e-01 -1.31379505e-01 -3.90003842e-01\n",
      "   3.97873476e-01  7.41751291e-02 -2.38868951e-02 -1.06351791e-01\n",
      "   4.24205330e-01 -1.99173271e-01 -2.53787667e-01 -5.83551094e-02\n",
      "   1.58804253e-01 -2.28994311e-01  1.54105468e-01  1.27826241e-01\n",
      "   3.34225966e-01 -1.71905611e-01 -2.07692869e-01 -1.37845441e-01\n",
      "   6.21971376e-03 -2.32655458e-01  2.10068748e-01 -2.03901680e-01\n",
      "   2.92114136e-01  1.60218659e-01  4.73631000e-02  5.00978229e-02\n",
      "   4.17639210e-02  5.21536333e-02 -1.40717019e-01 -8.30889595e-02\n",
      "  -7.64703476e-02  3.92053819e-01  2.71075201e-01  4.53487304e-02\n",
      "  -4.01683629e-01  5.19184609e-01  2.35447599e-01 -3.38874978e-01\n",
      "  -4.43774827e-01 -1.81741552e-01  4.14561777e-01  2.84829423e-02\n",
      "  -2.13979768e-01  2.88523990e-02]\n",
      " [-1.70522070e-01 -1.01707412e-02  1.52190100e-01 -1.75504232e-01\n",
      "   1.26751546e-01 -5.28799365e-02 -3.82316351e-01  1.72300052e-01\n",
      "   1.25104368e-01 -1.55495080e-01 -4.33880145e-02 -5.12438672e-01\n",
      "   2.43661948e-02  4.12540077e-01 -3.47520155e-01  9.56201499e-02\n",
      "   2.35884007e-01  4.30538453e-01  1.98035212e-01 -5.18560891e-02\n",
      "  -3.73627782e-01 -5.91481400e-01 -3.43146412e-01  1.54467622e-02\n",
      "   1.59267028e-01 -1.10056193e-01  9.24822246e-02  1.92555037e-02\n",
      "  -1.85129730e-01 -6.00297302e-02  2.29690864e-01  2.98821981e-01\n",
      "  -1.56062674e-01 -3.39673776e-01  2.66124308e-01 -2.52730328e-01\n",
      "   1.38461917e-01  1.46099529e-01  3.09039150e-02  1.72547357e-01\n",
      "   3.18861208e-01 -2.41381701e-01 -2.41094521e-01 -3.55455332e-01\n",
      "  -3.01683072e-01 -4.45514460e-01  7.50350860e-02  1.48251628e-01\n",
      "   6.64474138e-02 -3.51524465e-01]\n",
      " [-4.15594847e-01  1.38389326e-01 -6.47669226e-02 -2.08573855e-01\n",
      "   2.09376007e-02  6.53683024e-01 -4.46518599e-01  1.40042605e-01\n",
      "   3.93699720e-01 -6.39472419e-02 -2.16840612e-01 -1.57284893e-02\n",
      "   8.02154659e-02  9.61137961e-02 -3.16168270e-01 -3.35390487e-01\n",
      "  -4.53971031e-01  2.68105889e-02 -2.10776387e-01  6.50582759e-02\n",
      "  -1.15346029e-01  5.41681716e-01  5.78039626e-02 -3.27914889e-02\n",
      "   2.07163374e-01  4.21953839e-01  4.46266612e-02 -4.09976160e-01\n",
      "  -3.27296133e-01  2.15335176e-01  1.10725875e-03 -9.33532052e-02\n",
      "  -4.29430917e-02 -2.17446798e-01 -2.80356037e-01  3.33641476e-02\n",
      "  -2.29401262e-01 -5.97743464e-02 -2.18669103e-02  3.54252158e-02\n",
      "  -1.75905484e-01 -2.86495404e-01  1.18450669e-01  2.03325529e-01\n",
      "   2.95312324e-01  1.67687681e-01 -4.70767630e-01 -2.55092033e-01\n",
      "   4.60236459e-02 -2.14950726e-02]\n",
      " [ 4.72356405e-02  9.96034185e-02  2.57953711e-01  1.33097636e-01\n",
      "   1.26522137e-01 -1.86248091e-01 -3.05783959e-02  1.97742440e-01\n",
      "   1.83654761e-01  1.93604064e-01 -2.78197041e-02  3.35353356e-01\n",
      "  -4.58221410e-02 -4.24550700e-01 -2.15787699e-01 -1.77904134e-01\n",
      "  -3.09267501e-01  7.59508457e-02  2.70666673e-01 -5.60085771e-01\n",
      "  -2.41652073e-01 -2.62700709e-01 -2.81955194e-01  1.84716406e-01\n",
      "  -2.81068946e-01  9.49856794e-02  6.72707645e-02  3.17086618e-01\n",
      "   2.88327735e-01  1.98915449e-01  2.17590427e-02 -5.23878345e-02\n",
      "   1.21561361e-01 -1.59657604e-01  3.07486250e-01 -2.12210717e-02\n",
      "  -2.02285374e-01 -1.69797056e-02  1.93872173e-01  1.01935531e-01\n",
      "  -5.03326551e-01  3.88257292e-01  3.43567213e-01 -3.39432019e-01\n",
      "   1.70708114e-01 -1.58354917e-01 -2.51328434e-01  2.42059478e-02\n",
      "  -1.74156435e-03  1.28399396e-01]\n",
      " [-1.27564262e-01  4.76530113e-01  2.08167290e-01  3.37488171e-01\n",
      "   6.27468028e-01  2.09331011e-01  9.35010339e-02  6.17440949e-02\n",
      "  -4.20851452e-04  7.28305934e-01 -8.83506707e-02  2.69438270e-02\n",
      "   3.04260494e-02  4.10109980e-01  3.61138276e-01 -2.35821324e-01\n",
      "   2.10158936e-01 -3.39263815e-01  8.15504426e-02 -3.16053478e-01\n",
      "   8.32295753e-02 -5.80090668e-02  1.43196156e-01  8.38283359e-02\n",
      "   3.13387675e-01  1.07726835e-01 -1.49903326e-01  1.29925738e-01\n",
      "   1.04060200e-01 -5.84386838e-01  7.92478864e-01  2.61207840e-01\n",
      "   1.48522926e-01 -3.09116910e-01 -2.59959791e-01  3.85216995e-01\n",
      "  -1.87102181e-02 -3.67964727e-02  1.87724859e-01 -5.25725057e-02\n",
      "   2.21802254e-01  9.96378577e-02 -3.19289358e-01  2.93950760e-01\n",
      "  -1.60186351e-01 -1.24201257e-01 -5.54532940e-02 -4.29919217e-01\n",
      "   4.26789405e-01 -3.71276215e-01]\n",
      " [ 3.31021385e-01  1.29133089e-01  5.56194163e-01  1.90801912e-01\n",
      "  -1.20337489e-02 -4.25739681e-02 -1.68286948e-01 -2.31083607e-01\n",
      "  -6.49378048e-02 -1.19362400e-01  3.38156713e-01  1.80248390e-01\n",
      "   6.97452086e-02 -1.68312862e-01 -2.66476464e-01  8.10205782e-02\n",
      "   6.92694693e-02 -2.09533123e-01 -8.35104304e-02  2.98537984e-01\n",
      "  -4.87987403e-02  1.10166404e-01 -1.50520037e-01 -2.35071932e-01\n",
      "   2.17530998e-02 -1.81606199e-01 -1.56311105e-01  2.52740795e-01\n",
      "   7.39821870e-02 -6.72287514e-02 -3.75535780e-01  3.34099386e-01\n",
      "   1.73806210e-01 -1.38687595e-03 -9.18257948e-02 -1.03886760e-01\n",
      "  -2.73933419e-01  7.14500426e-02  4.07247422e-02  4.57744846e-02\n",
      "   4.75991752e-01  2.68565371e-01  2.71538462e-01  3.96739681e-01\n",
      "  -3.91841863e-01  2.58222726e-01  1.55009244e-01 -1.60558688e-01\n",
      "   2.21492845e-01 -2.47391338e-01]\n",
      " [ 1.67793407e-01  8.88026071e-02  5.67962019e-02 -1.95313700e-01\n",
      "   1.28186209e-01 -9.97518363e-02  3.53943885e-01 -1.41609037e-01\n",
      "   2.54405173e-01  3.10389256e-01 -2.53097320e-01 -2.46236939e-01\n",
      "   2.76300238e-01 -9.38701338e-02  2.18270872e-01 -3.23764917e-02\n",
      "   1.05038106e-01  3.77883446e-01  7.91425867e-02 -1.33071495e-01\n",
      "  -1.08191473e-01 -1.36381062e-02 -1.23479953e-01  1.10095267e-01\n",
      "  -1.55307077e-01  1.00228938e-01  1.83346140e-01  4.47815500e-02\n",
      "   8.46790465e-02  9.77500009e-02 -1.56493578e-01  5.13194804e-01\n",
      "   2.48516470e-01  1.03208091e-01 -1.23877408e-01  1.36100278e-01\n",
      "   9.17273529e-02 -3.11416681e-01 -3.86981997e-01  1.08839944e-01\n",
      "  -1.82094742e-01  3.15334967e-01 -5.27396668e-01 -5.01043498e-01\n",
      "  -1.01596922e-01  2.36116430e-01 -2.77734500e-01 -1.06428128e-01\n",
      "  -8.79524678e-02 -2.37644067e-02]\n",
      " [ 2.26935193e-01  5.02717530e-01 -4.56951216e-01  1.07905118e-01\n",
      "   1.45204592e-01  4.59067024e-01 -3.26925054e-01 -2.14300291e-01\n",
      "  -5.12981318e-03  4.59367040e-02 -3.96198059e-01  1.37033937e-01\n",
      "   1.17308760e-01 -1.59278878e-01  8.29923513e-02 -2.29112517e-01\n",
      "   4.00462904e-01 -1.05092581e-01  7.63699670e-02  5.63703590e-02\n",
      "  -2.78815111e-01  4.16484250e-02 -3.10222626e-01 -2.13215167e-01\n",
      "  -2.93048940e-01  1.24458671e-02 -4.06330548e-01  2.83865860e-01\n",
      "  -2.07554727e-01  4.06020511e-01 -2.09398107e-01 -6.45856876e-01\n",
      "   4.45371712e-02 -8.65849215e-03  5.16142973e-01 -4.07432538e-01\n",
      "  -5.18066524e-03 -3.63089849e-01  4.30609825e-01 -1.59523627e-01\n",
      "  -1.22399902e-01 -6.03820082e-01 -1.39249589e-01 -5.42469672e-01\n",
      "   1.37846927e-01  1.25680998e-01  2.18688272e-01  1.71571807e-01\n",
      "  -4.50098604e-01 -7.02882009e-02]\n",
      " [-4.84116865e-01  2.35306469e-02 -1.58600140e-01  2.15705874e-01\n",
      "   1.32210376e-01  8.27977001e-02  2.66032629e-01 -8.75341045e-02\n",
      "  -2.87459884e-01 -3.96055393e-01 -3.74961541e-01  6.21095768e-01\n",
      "  -1.34443981e-01 -1.67993169e-02 -1.72182931e-02 -2.14638340e-01\n",
      "  -9.29138968e-02 -5.74281499e-01  3.69612862e-01  7.95225096e-03\n",
      "   2.40794571e-01  6.50471918e-02  1.11521405e-01  2.76237737e-01\n",
      "   1.60925194e-01 -3.05863037e-01  2.07401125e-02  2.11552799e-01\n",
      "  -4.37245628e-01 -3.46831213e-03 -2.04023306e-02  3.18831588e-01\n",
      "   1.39366725e-01  4.30333588e-01 -9.37771799e-02  4.93475211e-01\n",
      "   1.42124445e-01 -3.59976292e-01 -6.46962024e-02 -8.89088078e-01\n",
      "   4.21974223e-02  2.18853991e-01  2.54025741e-01 -4.23061121e-04\n",
      "  -6.50776837e-02  2.65928095e-01  2.10994722e-01  3.40680753e-01\n",
      "   5.11839398e-01  2.60812170e-02]\n",
      " [-2.06524126e-01  2.20594928e-01  3.39653361e-02 -1.73248552e-01\n",
      "  -1.69343539e-01  8.45157183e-02  1.97921990e-01 -3.87106518e-01\n",
      "   2.43035885e-01 -2.58503907e-01 -2.14950050e-02 -1.58660601e-01\n",
      "  -2.91176367e-01 -1.40435455e-01  1.94933046e-01 -2.85148773e-02\n",
      "   2.59344224e-02 -3.74704951e-01 -6.45526777e-02 -4.83673101e-02\n",
      "   2.07539329e-01  2.62917725e-01  5.19721825e-01  2.74856428e-01\n",
      "   5.50293334e-02 -1.03059833e-01 -2.28587972e-01 -2.09303827e-01\n",
      "  -2.02715345e-01  1.44657607e-01 -6.16871826e-02 -2.45034335e-01\n",
      "   3.28129617e-01  2.78494787e-01  1.71675912e-01  3.37094131e-03\n",
      "   2.36249875e-01 -8.74520369e-02 -3.87752718e-01 -1.68497969e-01\n",
      "   1.63225789e-01  1.72177339e-01  9.42031977e-02 -2.57282276e-02\n",
      "  -1.93828634e-01 -3.52704090e-01 -6.62853227e-02 -1.81231292e-01\n",
      "   3.37866082e-01 -1.14190088e-01]\n",
      " [-1.53310657e-01  2.99653981e-02  4.17849656e-01 -9.04893450e-02\n",
      "   3.66051237e-02 -8.19953986e-02  1.14951315e-01  9.52043915e-03\n",
      "   9.44489906e-02  7.78492062e-02 -3.66618153e-01 -1.31116184e-01\n",
      "  -1.16695445e-01 -3.75486465e-01  2.79009843e-01  1.22245156e-02\n",
      "  -1.68594582e-01  5.27189767e-02  4.56725356e-01 -5.55503606e-01\n",
      "  -1.55351363e-01  1.51209763e-01  7.27629620e-02  1.80724742e-01\n",
      "   1.42786566e-01 -3.39740403e-02 -9.60856751e-02  1.22265677e-01\n",
      "   2.60163898e-01 -1.95485389e-01  3.23813370e-01  2.08215892e-02\n",
      "  -8.05685440e-02 -3.98603738e-01  1.33359121e-01 -2.97673312e-01\n",
      "   1.24513749e-01 -3.37838791e-01 -5.05655101e-01  8.03104345e-02\n",
      "  -1.37853786e-01  1.84889839e-01 -1.12942272e-01 -2.42256965e-01\n",
      "  -1.87290629e-01 -2.45867366e-01 -3.03236120e-01 -2.52945998e-01\n",
      "  -4.57643600e-01 -1.88360117e-01]\n",
      " [ 1.78401671e-01  7.84236718e-02 -4.46500801e-01 -1.76201409e-01\n",
      "  -2.87275229e-02 -1.02311683e-02  5.08948515e-02 -1.07236764e-01\n",
      "  -3.25102741e-01  3.37473677e-01  3.65963138e-02  3.59316305e-02\n",
      "   1.29274065e-01 -6.64932853e-02 -2.45545388e-01  4.12601360e-01\n",
      "  -1.11840535e-01  5.47566633e-03  3.48349392e-02 -7.43061994e-02\n",
      "  -2.48383365e-01  1.27336939e-01 -1.97908845e-01  9.64936424e-02\n",
      "   2.78568032e-02  2.59107597e-02  6.33460574e-02  2.57921786e-01\n",
      "  -2.88829357e-02 -2.78304557e-02 -3.29505377e-01  3.29325868e-01\n",
      "   2.30099813e-01  2.50220526e-02 -1.41892112e-01 -3.18659379e-01\n",
      "   3.28997147e-01 -1.64003840e-01 -1.06515646e-01 -6.51997166e-02\n",
      "  -6.50682576e-02  4.26816663e-01 -9.81152392e-02  1.26365263e-01\n",
      "  -8.07710528e-02 -4.40417975e-01 -4.25007942e-01 -3.25702633e-01\n",
      "   1.99757157e-01 -1.49357213e-01]\n",
      " [-1.00375088e-01  7.81988626e-02  2.06110188e-01 -5.01564642e-01\n",
      "   4.59408730e-01 -5.21243954e-01  9.76779229e-02 -1.03748374e+00\n",
      "  -1.93235163e-01 -2.46310545e-01  7.68448446e-02  3.89839846e-01\n",
      "  -8.93056542e-01 -1.56884956e-01 -2.54629945e-01  7.52206078e-02\n",
      "  -1.86086013e-02 -1.36734524e-01  6.67845148e-02 -2.90245222e-02\n",
      "   1.01411829e-02  1.82843512e-01 -3.22602600e-02  8.86861013e-02\n",
      "   3.78408622e-02  2.31325590e-01 -2.68475464e-01 -2.63929784e-01\n",
      "   1.46522628e-01  2.06173682e-01  4.43254010e-02  1.52954934e-03\n",
      "   2.85494918e-01  7.20700939e-01  3.25871217e-01  2.35261446e-01\n",
      "   1.08647298e-01 -1.04054195e-01  2.17941848e-01  1.01173100e-02\n",
      "  -3.33701517e-01  1.26067139e-03  1.16448946e-01 -6.92138402e-02\n",
      "  -2.76663677e-01 -4.41707959e-01 -1.49322803e-01  3.84574594e-01\n",
      "  -4.15528831e-02 -2.17410745e-01]\n",
      " [-1.54143183e-01  4.73085173e-01  2.48711238e-01 -3.36548478e-01\n",
      "  -1.06502693e-01  1.20792220e-01  1.62933951e-01  1.86997384e-01\n",
      "  -2.29174727e-01  3.37763832e-01 -1.35745827e-01 -3.97375977e-01\n",
      "  -3.47612987e-01 -6.08755300e-02  1.14475496e-01 -2.84997036e-01\n",
      "   1.35183753e-01  3.05843131e-01 -8.05424611e-02 -3.98243508e-01\n",
      "  -1.80619603e-02  3.90668234e-01  5.34703634e-02  3.51536467e-01\n",
      "  -5.34740266e-01  7.59757722e-02  2.23372727e-01 -3.66422129e-01\n",
      "   7.44402038e-02  2.90322635e-01  1.81399480e-01  3.43207778e-01\n",
      "  -1.16235040e-01 -1.36555559e-01  3.34438299e-02 -9.17716391e-02\n",
      "   4.30838301e-01 -4.42077046e-01  1.78679701e-01 -1.18569075e+00\n",
      "   4.45725431e-01 -2.17475184e-01 -7.19008824e-01  2.85558042e-01\n",
      "  -2.31987953e-01  4.05873480e-01  3.69903059e-01  2.09603724e-01\n",
      "  -1.40324360e-01  5.00548449e-01]\n",
      " [-1.58537890e-01 -2.35083404e-01 -3.53010934e-03  3.73450485e-01\n",
      "   1.53178173e-01  1.24702680e-01 -3.09223565e-01 -5.43677180e-02\n",
      "  -1.20717074e-01  1.25618975e-01 -5.23667148e-01  3.63272834e-01\n",
      "  -2.32248700e-01 -2.93415106e-01 -2.18881762e-02 -9.26644125e-02\n",
      "  -2.78889607e-02  3.85732409e-02  1.47098320e-01 -2.96308956e-01\n",
      "   2.20007426e-01  1.73993735e-01  1.05451949e-01  2.04686767e-01\n",
      "   4.92843164e-02 -1.84082213e-01 -1.90368383e-01 -1.28451371e-01\n",
      "   1.02993863e-01  5.02771126e-02 -5.61854805e-02  9.13936408e-02\n",
      "  -2.25724366e-01  8.35519164e-02  4.81476295e-01 -2.00174115e-01\n",
      "   3.77710397e-01  9.87719800e-02 -8.51489786e-02  4.15114382e-02\n",
      "   9.75137383e-02  1.50917517e-01 -1.39868979e-01 -3.11129780e-03\n",
      "   4.31823088e-01  3.32889512e-01  9.12410504e-03 -3.46824565e-01\n",
      "  -2.63529935e-01  1.39566680e-01]\n",
      " [ 2.40670554e-01 -6.57656784e-02  2.69608601e-01  3.22405271e-01\n",
      "   2.36288763e-01  2.50531922e-01 -6.59107466e-02 -4.77546659e-01\n",
      "   4.93043893e-02 -5.99396599e-02 -1.54551068e-01  7.55701013e-02\n",
      "   3.33662646e-01  2.79626262e-02  3.04675864e-01 -1.72333685e-01\n",
      "  -8.23324537e-02 -2.81741348e-02 -1.62882284e-01  4.24231502e-01\n",
      "   1.45942808e-01 -1.92769619e-01  1.32946555e-01  1.93743907e-02\n",
      "  -2.94263569e-02 -5.90932986e-01 -9.38660123e-02 -1.92467317e-01\n",
      "   3.33090434e-01  3.01992286e-01 -8.85820300e-02  2.68775273e-01\n",
      "  -7.62235797e-02 -3.75089932e-02  8.71585131e-02  3.27348313e-01\n",
      "  -2.00824740e-01  2.61154488e-01 -4.69081953e-03 -2.28902564e-01\n",
      "  -2.21632321e-01  4.55020887e-01 -4.10411101e-01  1.13079663e-01\n",
      "   7.71636113e-02  3.72101856e-01  9.08326324e-02 -6.48519992e-02\n",
      "  -1.53502991e-01 -1.94344815e-01]]\n",
      "\n",
      "weights between first hidden and second hidden layer:\n",
      "[[-1.49008828e-01  2.01004766e-01 -2.40381561e-01  3.94048137e-01\n",
      "  -1.09697173e-01  1.33741560e-01  4.08339641e-01 -3.00190172e-01\n",
      "   8.04025407e-03 -4.17883866e-01  4.45168397e-02 -1.28885322e-01\n",
      "   7.56292790e-02  2.75268609e-01  6.40547000e-02  1.31502696e-01\n",
      "   1.08008218e-01  1.16485655e-01  2.51843443e-03 -3.68110725e-02]\n",
      " [-2.04479478e-01 -2.21170373e-01 -2.92836448e-01  1.95098842e-01\n",
      "   4.59698021e-02 -1.03704374e-01  2.68342311e-01 -2.27141972e-01\n",
      "  -6.87306553e-02 -2.47466743e-02 -4.34109586e-01  1.42687673e-01\n",
      "  -3.29377840e-01 -8.46047667e-02 -1.99260620e-02  9.10133133e-02\n",
      "  -1.19009771e-01  1.44232049e-01 -6.25145959e-04  4.30452596e-03]\n",
      " [-2.08682128e-01 -8.79269189e-02 -1.73217563e-01  1.70526582e-01\n",
      "  -4.78209438e-01 -9.30715010e-02 -1.22514116e-01 -3.03671834e-01\n",
      "  -2.97363265e-01  1.10870110e-01 -2.83375448e-02 -1.29509573e-01\n",
      "  -2.49333543e-01 -8.20440880e-02 -2.94428468e-01 -5.05509056e-01\n",
      "  -1.34493708e-01 -1.48157042e-01 -3.01820510e-01 -4.95498434e-02]\n",
      " [ 2.88940521e-01  2.40880477e-01  2.94826433e-01  2.06990643e-01\n",
      "  -4.37160800e-01 -2.14015225e-01 -2.75875486e-01 -9.27986798e-02\n",
      "   2.50653349e-01 -1.61737248e-01  9.33676031e-03  1.98053455e-01\n",
      "  -8.56316511e-03  3.72561548e-01 -1.34255140e-01 -3.71333707e-01\n",
      "   5.42690566e-03  1.00777521e-01 -5.08441417e-02  1.85581379e-01]\n",
      " [-2.09158591e-01 -2.43633625e-01  2.16986075e-01 -7.31889072e-02\n",
      "  -1.61273422e-01  6.23336806e-02  7.88474355e-02 -1.83629607e-01\n",
      "   2.01789950e-01  4.60922488e-01  9.04861325e-02 -2.42312409e-01\n",
      "  -2.47213200e-02  3.23925065e-01  2.33582930e-02  4.03839397e-01\n",
      "   6.67202237e-02  1.36225885e-01  7.95315807e-02  8.71212146e-03]\n",
      " [-1.01995120e-01  1.17743963e-01  6.02088529e-02 -1.12901935e-01\n",
      "  -9.94093237e-02 -7.75688025e-02 -4.61948366e-01 -1.93862920e-01\n",
      "  -2.70660895e-01  1.53478835e-01  2.15118712e-02  7.65648322e-02\n",
      "   5.73515500e-02  2.21007710e-01 -2.83335334e-01 -1.42812694e-02\n",
      "  -3.83084816e-01 -1.06236578e-01 -5.95993687e-01  2.73322083e-01]\n",
      " [ 7.06220627e-03  3.08037901e-01 -2.75100311e-02  8.65873364e-02\n",
      "  -1.44023549e-01 -5.30123164e-01  9.38195112e-02  4.75516953e-02\n",
      "   1.89130992e-01  4.85455306e-01 -1.00201202e-01 -6.23577686e-02\n",
      "  -2.52670472e-01 -9.25779547e-02  3.05824101e-01 -4.39847106e-01\n",
      "  -3.86048203e-02 -8.13535643e-02  2.47146753e-02  4.23581525e-01]\n",
      " [-2.67421129e-01 -6.85274883e-03 -1.87768909e-01  4.68576639e-01\n",
      "   2.48825780e-01  1.59165504e-03  1.15124253e-01 -1.17716806e-01\n",
      "   2.34725830e-01 -1.78976286e-01 -1.65858671e-01  5.64680358e-01\n",
      "   8.79522471e-02 -4.80488970e-01  1.58288296e-01 -3.23312903e-01\n",
      "  -1.74666272e-01  4.00196713e-01 -6.14798422e-01  3.66748725e-01]\n",
      " [ 1.84221912e-01 -2.14851756e-01 -5.11733980e-01  9.51186609e-02\n",
      "  -2.98745181e-01 -2.58307501e-01 -2.18034636e-01 -1.34790250e-01\n",
      "   2.19281109e-01 -2.80170291e-01 -1.67808497e-01  1.10465742e-02\n",
      "  -1.98642050e-01 -3.09010964e-02  1.11178410e-01 -3.23191208e-02\n",
      "   3.66809852e-01  1.33788410e-01  1.26105785e-01  2.47958863e-01]\n",
      " [-1.27565927e-01  2.25254191e-02  2.47388329e-02 -5.95508541e-02\n",
      "  -6.72607671e-02 -2.08592104e-01 -3.33431698e-01 -3.65886726e-01\n",
      "  -2.02376117e-01  3.33213047e-01 -1.07384647e-01  3.96313242e-02\n",
      "  -9.82634154e-02 -7.62523775e-02 -7.99343069e-02  4.61155218e-01\n",
      "  -3.83000125e-01  4.53034837e-02  1.35291779e-01  1.90914924e-01]\n",
      " [-1.80020549e-01  1.62507563e-01 -4.54637973e-01  3.19007952e-02\n",
      "   2.20433803e-01  2.08823771e-02  2.58855543e-01  9.27899416e-02\n",
      "   1.88882703e-01  1.77534209e-01 -3.20837801e-01 -2.48737649e-01\n",
      "   1.29942487e-01  2.47352835e-02 -3.47196707e-01  1.96504545e-01\n",
      "  -3.68582928e-01 -4.51203081e-03  1.49936776e-01 -1.76338807e-01]\n",
      " [-1.15148848e-01 -4.00023518e-01  4.47642639e-01 -5.11592699e-02\n",
      "  -1.85786494e-02  4.47538865e-01 -1.80391231e-02 -1.63854319e-01\n",
      "   2.76918976e-02 -2.05243525e-01 -9.95729087e-02  1.81519206e-01\n",
      "  -1.47242399e-01  3.23729437e-01  1.41284215e-01 -2.49634600e-01\n",
      "  -3.35457358e-02 -1.40848724e-01  3.61517998e-01  5.57471408e-01]\n",
      " [-2.45890824e-01 -9.40436346e-02 -1.86192921e-02  9.90830149e-02\n",
      "  -4.76071777e-02  9.73993623e-02 -6.51229710e-02  6.92919953e-02\n",
      "   7.18249069e-02  3.30577761e-02  1.06929355e-01  3.48975579e-01\n",
      "   2.19501245e-01 -7.17896648e-01 -4.09425053e-01  1.45086945e-01\n",
      "  -1.46812488e-01 -8.69675226e-02 -1.79646744e-01  1.37051807e-01]\n",
      " [-4.23549308e-02 -3.99091778e-01 -2.71085419e-01  1.29384217e-01\n",
      "  -3.00374388e-01 -2.28377337e-02 -1.10746070e-01  9.98760697e-03\n",
      "  -5.20546752e-03 -2.00504626e-01 -2.34566580e-01 -1.48859493e-01\n",
      "  -2.11510990e-01 -1.54351782e-01  9.53044187e-02  2.38424070e-01\n",
      "   9.83553680e-02  1.08472962e-01  2.36652078e-01  1.75234934e-01]\n",
      " [ 9.19679874e-02  6.74960602e-03 -1.90751617e-01  1.15226205e-01\n",
      "   1.62646839e-01 -1.99878860e-01  3.08220474e-01  1.66018468e-01\n",
      "  -9.96956631e-02  2.23778288e-01  2.24187771e-01 -4.92028902e-02\n",
      "   2.34050037e-01 -2.84962263e-01  1.14020186e-01  3.80869706e-01\n",
      "  -1.48343894e-01 -1.77312112e-01  2.50717779e-02  4.18736203e-01]\n",
      " [ 1.88455475e-01  6.74609029e-02  1.96896002e-01  1.64463416e-02\n",
      "  -1.90053658e-01 -3.04658443e-02 -4.25999569e-02  2.96445292e-01\n",
      "  -7.01262448e-02  2.49319344e-01 -7.18093113e-02 -1.92964595e-01\n",
      "  -2.49103370e-01  1.12399514e-01 -3.26242149e-01  1.29014128e-01\n",
      "   4.65802330e-02  2.59930249e-01  3.03382441e-01 -1.51644728e-01]\n",
      " [-6.15505721e-02 -1.74787534e-01 -8.55449267e-02  3.83286625e-02\n",
      "  -1.32415173e-01 -6.89191982e-02  2.31255956e-01  2.51385866e-01\n",
      "  -2.79682224e-01  1.94033173e-01 -2.29504226e-02  4.94360201e-01\n",
      "  -7.67778845e-02  1.57304681e-01 -3.01742163e-01 -1.44066090e-01\n",
      "  -1.22807581e-03  2.12411307e-03 -2.30498339e-01  6.72285615e-02]\n",
      " [-1.59502244e-01 -1.43660087e-01 -2.83854105e-01  8.11400152e-02\n",
      "   3.13786537e-01 -7.30842166e-02 -5.74655122e-01  1.27002043e-01\n",
      "  -2.44447491e-03  4.83203821e-03 -1.87110635e-01 -2.94877090e-01\n",
      "  -7.71199533e-02  1.51493320e-01 -8.32685500e-02  1.16475282e-01\n",
      "   8.52117843e-02 -5.69890340e-02  3.60657142e-01 -2.07944333e-01]\n",
      " [-2.23563241e-01  1.02788965e-01  5.30877267e-02 -1.11019610e-01\n",
      "  -3.41291009e-01  3.24464352e-02  3.56454749e-01 -2.51224993e-01\n",
      "  -2.54070019e-01  1.16450548e-01 -1.24713947e-01 -9.58805688e-02\n",
      "  -1.32072046e-01  4.72669801e-01 -2.44646125e-03  1.90085827e-01\n",
      "  -1.26137095e-01 -2.64271108e-01 -2.44763121e-01 -1.52539515e-02]\n",
      " [ 1.41527673e-01  1.71565338e-01  3.96838862e-02 -4.84251414e-01\n",
      "   1.27223541e-02  2.17617874e-01 -2.88000213e-01 -2.84785579e-01\n",
      "  -1.84467075e-01  4.12046351e-01  2.76198871e-01  3.76244753e-01\n",
      "  -9.57264928e-02  1.19162757e-01  1.95797863e-01  4.34663082e-01\n",
      "  -2.86161350e-03  2.80047222e-02  2.31716989e-02 -2.06355081e-01]\n",
      " [ 2.16691233e-02 -1.48583592e-01  7.19982623e-02  2.34707447e-01\n",
      "  -5.81491862e-02 -5.95199410e-02  2.01243214e-01  1.10085037e-01\n",
      "  -6.19420491e-02 -1.70216912e-01  2.18580445e-02 -2.99983266e-01\n",
      "  -2.76977590e-02 -2.21621563e-01 -2.21664084e-01  1.79743149e-01\n",
      "   1.42384459e-01 -1.52642442e-02  1.38975843e-01  1.34844831e-01]\n",
      " [ 1.17420006e-01  4.21193829e-01  2.30359621e-01 -2.74236487e-01\n",
      "  -1.49769356e-01 -2.33149778e-01  3.83563881e-01 -1.23742905e-01\n",
      "   9.25962852e-02 -3.23756951e-01 -1.64464553e-01 -3.46774094e-02\n",
      "  -2.85674625e-01 -1.77671549e-01 -1.39742292e-01 -3.17817732e-01\n",
      "   2.11504548e-01 -1.52409431e-01  1.40998475e-01  8.87574304e-02]\n",
      " [ 1.04508501e-01  2.88692219e-01  7.06432107e-02 -6.34566674e-02\n",
      "   6.94910764e-02  2.45245275e-01  8.57543380e-02  2.74982466e-01\n",
      "  -3.45429454e-02  1.54938582e-01 -2.70108488e-01  2.21438991e-01\n",
      "   4.85779345e-03 -2.91348820e-01 -1.25768028e-01 -2.68723712e-01\n",
      "   2.00880423e-01 -2.51113950e-01 -1.49522276e-02  2.82975119e-01]\n",
      " [ 8.75867654e-02  2.57278971e-01 -1.95031909e-01 -1.05542299e-02\n",
      "   1.66776469e-01  2.20437696e-01  2.94879709e-01  7.07894278e-02\n",
      "   2.29641331e-01  4.34051060e-01  3.32908559e-01 -2.59673141e-01\n",
      "  -2.49795388e-01 -2.99817574e-01 -1.65854752e-01  5.12842001e-01\n",
      "  -2.77908001e-02  3.14948395e-01  1.31228302e-01 -1.87420691e-01]\n",
      " [-8.97661802e-02 -4.74113948e-02 -8.66216423e-02  3.62823207e-01\n",
      "  -7.47361320e-03 -4.38019108e-01 -3.99470662e-02 -2.69119890e-02\n",
      "  -2.75858478e-01  3.07924780e-01  3.83633983e-01  2.07244862e-01\n",
      "   1.41505752e-01 -1.99778929e-01 -2.44133140e-01 -1.07423015e-01\n",
      "   7.25345090e-02  8.33572219e-03  3.49237238e-01  3.16888455e-01]\n",
      " [ 1.05587745e-02 -2.20345108e-01  1.50794373e-01  1.49765677e-02\n",
      "   1.00316887e-01  2.95882201e-01  1.25992939e-01 -1.37008003e-01\n",
      "  -2.46683089e-01 -1.06049008e-01  1.37025567e-01 -6.74775487e-02\n",
      "   1.15642806e-01  1.04078460e-01 -2.76668462e-03  8.26248341e-02\n",
      "   1.88219015e-01  3.42749852e-01 -4.29173598e-01 -2.92338717e-01]\n",
      " [-2.89375076e-01 -9.52632188e-02 -2.62599131e-01 -8.63471782e-02\n",
      "  -7.96836106e-02  2.77428045e-01 -1.94843015e-02 -1.26917727e-01\n",
      "   1.75965997e-03  9.08321239e-02 -2.32673596e-01  1.48496995e-01\n",
      "   2.06078100e-01  2.26196702e-01  2.23972862e-01 -9.09918479e-02\n",
      "  -3.43058090e-02 -2.51400037e-01 -1.45666209e-01  2.68827844e-01]\n",
      " [-1.26111142e-01  2.05339245e-01  1.80863428e-01  1.84415212e-01\n",
      "  -1.73177248e-01  2.73489447e-01 -2.45234021e-01 -1.80038300e-01\n",
      "  -8.93581582e-02 -1.87795828e-01 -4.47632785e-02 -3.47663935e-01\n",
      "  -1.95641895e-01 -1.60123814e-01  4.55326941e-02 -1.39762414e-02\n",
      "   3.65289133e-01 -2.22106195e-01  6.72184089e-02 -3.30968239e-01]\n",
      " [ 9.48483644e-03  6.92643099e-02  2.30435963e-01 -5.98338723e-01\n",
      "  -7.88622735e-03 -2.77034568e-01 -1.02034403e-01 -2.81390208e-01\n",
      "  -1.29992180e-02 -2.26565202e-01 -5.36222972e-01 -1.00402942e-01\n",
      "  -1.12910328e-01 -6.20303670e-02 -1.59761713e-01 -6.58608550e-02\n",
      "   1.49162120e-01 -3.95784789e-02  4.46534737e-01  6.47756944e-03]\n",
      " [-1.24694150e-01 -3.30912626e-01  8.86505313e-02  2.52440779e-01\n",
      "   1.96693349e-01  1.24748999e-01  2.06356946e-01  3.30145886e-01\n",
      "  -1.42125394e-01 -3.19451786e-01  3.00557069e-02 -1.12853958e-01\n",
      "  -3.98298991e-02 -3.71823272e-01  4.94214051e-01  1.72107894e-01\n",
      "   1.36772796e-01  1.26388301e-01  2.44613631e-01  6.93714290e-02]\n",
      " [-2.08926425e-01 -2.03881664e-02  8.08918281e-02 -3.56693183e-01\n",
      "  -3.60202268e-01 -6.01057475e-02 -2.08039720e-01  1.01656588e-01\n",
      "  -1.41022360e-01 -7.06771028e-02 -5.48995233e-01  1.74597387e-01\n",
      "   2.78429767e-01 -6.97519828e-01 -1.79584353e-02 -8.33803040e-02\n",
      "  -3.09901958e-01 -1.90364205e-01  1.33118650e-02 -2.48587086e-01]\n",
      " [-1.23396273e-01  3.33599947e-01 -1.21530764e-01 -2.72301432e-01\n",
      "  -6.00323924e-02 -9.12294712e-02  2.36152966e-02 -3.10087142e-01\n",
      "  -1.43647947e-01 -3.12277134e-01  2.67732126e-01 -1.52867885e-01\n",
      "  -8.30880236e-02  3.09865593e-01 -1.22061378e-01 -3.04977076e-01\n",
      "  -5.07077122e-01 -4.88922120e-01 -3.39395281e-02  1.95051549e-01]\n",
      " [-2.41131755e-01 -3.56088108e-02 -3.15894788e-01 -1.89051322e-01\n",
      "   3.60014194e-01  5.84812665e-02  2.72307726e-01 -2.41089082e-01\n",
      "  -2.93621360e-01  2.06595323e-01  1.15202731e-01  2.72851036e-01\n",
      "   9.39630136e-02 -2.59569398e-02  4.02817454e-01 -6.39954938e-02\n",
      "   4.64037746e-02  1.56612973e-01  3.70277406e-02 -2.21758314e-01]\n",
      " [ 1.18944332e-02  2.32682180e-01 -2.54261536e-01  2.28857963e-01\n",
      "   1.27887467e-02 -1.94794301e-01 -4.98406762e-02  1.67839188e-01\n",
      "  -1.43604128e-01  4.91557513e-02  3.86029574e-01 -6.15074476e-01\n",
      "  -2.42915917e-01 -5.16580832e-02 -3.17603951e-01  2.69969732e-01\n",
      "  -4.59191119e-02  7.60473471e-02 -4.10660202e-01 -3.16927595e-01]\n",
      " [ 7.32633096e-02 -2.90135609e-01 -2.94686263e-01  1.20784212e-02\n",
      "   3.15957727e-01 -1.12073685e-01  3.14441810e-01  4.73015889e-01\n",
      "   2.51597115e-01 -1.95757635e-01 -8.65315393e-02  2.14883777e-01\n",
      "  -1.02222354e-01 -2.53521950e-01  7.89437107e-02 -7.62533202e-02\n",
      "   1.29775282e-01 -2.60343175e-01  7.85988164e-02  4.75466152e-01]\n",
      " [-2.92164855e-01  1.98449606e-01  2.18467375e-02 -3.91822484e-02\n",
      "  -6.63618273e-01  3.42916389e-01 -1.14021532e-01  1.53128635e-01\n",
      "  -2.76421550e-01  4.09925210e-02  1.40880511e-01  7.49742078e-02\n",
      "  -5.33410822e-02 -5.28562559e-01  1.74350656e-03 -2.39964307e-01\n",
      "  -3.00014272e-01  4.04416510e-02  3.68342071e-01 -3.67962570e-02]\n",
      " [ 2.02628587e-01  3.80213811e-01  2.92871141e-02  2.43751333e-01\n",
      "  -3.78353726e-01  1.83404658e-01 -4.84916617e-01  1.61188430e-01\n",
      "  -1.10698264e-01  1.58641412e-01  6.14534540e-02  2.16964302e-01\n",
      "  -1.94262914e-01 -3.17865357e-01  2.65623684e-01  8.80972379e-02\n",
      "  -1.47112793e-01  2.71423285e-01 -1.58297527e-01  9.35163018e-02]\n",
      " [ 3.12875379e-02 -1.96330825e-01 -1.47847794e-01  4.77108655e-02\n",
      "   1.47314495e-01  1.66413101e-01 -1.38877907e-01 -6.47477936e-03\n",
      "   8.35159450e-02  3.86820234e-01 -2.78075258e-01  8.92937842e-02\n",
      "  -1.45875739e-01  3.20191312e-01  3.15552140e-01 -1.55885069e-01\n",
      "   2.22527309e-01  1.41574159e-02  1.24564201e-01  1.75118486e-01]\n",
      " [ 8.84208981e-02 -2.41307638e-01  6.91603145e-02  1.72078574e-02\n",
      "   3.16772475e-04  3.86042359e-01 -3.78634209e-01  2.74726203e-01\n",
      "   1.31900644e-01 -3.20281727e-02 -5.76343190e-01  1.75754430e-01\n",
      "  -1.68387647e-01  4.29737284e-03  4.75902998e-02  4.93776518e-02\n",
      "  -2.78586144e-01  3.29954855e-01  3.74127970e-01  2.22281229e-01]\n",
      " [-2.39831231e-01 -4.04185008e-01 -3.64014842e-01 -3.11231998e-01\n",
      "  -2.03565431e-01 -1.01355411e-01 -4.41473641e-02 -8.06202198e-02\n",
      "   2.18713541e-01  2.49804817e-01  1.48735032e-01  5.41078879e-01\n",
      "  -3.05117953e-01  3.81898718e-01 -8.86341231e-02  9.47601441e-02\n",
      "   7.48973593e-01  2.09498551e-01 -1.79455065e-03  4.33328607e-01]\n",
      " [-1.41763186e-01  2.98701053e-01  6.53334899e-02  3.35076290e-01\n",
      "  -2.78055179e-01  8.76684922e-02 -8.86735735e-02 -1.60048740e-01\n",
      "  -1.41211961e-01 -1.06817527e-01 -2.01127263e-01 -3.06733496e-01\n",
      "   1.78725403e-01  7.55120269e-02 -4.78559075e-01  3.33184310e-01\n",
      "  -1.18953819e-01  1.49039970e-01  1.14672720e-01 -5.97057271e-02]\n",
      " [ 2.84716627e-01 -3.19396903e-01 -5.58367931e-03  1.44540621e-01\n",
      "  -4.92273739e-02  7.51532982e-02  3.17047485e-02 -2.19999054e-01\n",
      "   1.69964879e-01 -4.62332059e-01 -9.43624420e-02  2.32714770e-01\n",
      "   2.64178248e-01 -2.55319386e-01  3.62378958e-01 -4.84320681e-01\n",
      "   1.59432278e-01 -1.90926978e-01 -1.86616583e-01 -4.46902171e-01]\n",
      " [ 2.86742694e-01  4.87873527e-02  2.69608258e-01 -2.66799996e-01\n",
      "   1.07914639e-01 -3.70815182e-01  1.53688658e-01  1.27853019e-01\n",
      "   2.51216452e-02  7.71626326e-01 -1.78393797e-01 -5.76759762e-02\n",
      "  -6.15062918e-02  2.06979350e-01 -9.52634831e-02  2.00961430e-01\n",
      "  -1.99390336e-01 -3.10059036e-01 -7.30252988e-02 -1.19549522e-01]\n",
      " [-6.12764160e-02  3.77651649e-01 -4.37605911e-01 -6.89586681e-02\n",
      "  -2.85650218e-01  2.07627760e-02  4.01988472e-02 -1.54911037e-01\n",
      "  -2.67165471e-01 -2.91204839e-02  2.63163438e-01 -2.16049156e-02\n",
      "   9.65628206e-02 -1.92469588e-01  3.29809263e-01  6.04390538e-01\n",
      "   1.88349335e-02  1.58232364e-02 -1.62360412e-01  2.69589508e-01]\n",
      " [ 2.54875778e-01  2.25945226e-01  6.08750378e-02  7.93815836e-02\n",
      "   8.91630786e-02  2.82836121e-01  1.12516231e-01  1.43214300e-01\n",
      "  -8.70028109e-02  5.22814742e-01  1.85541949e-01 -9.92537414e-02\n",
      "   1.87524463e-01  2.07133081e-01  1.66437841e-01  1.66793611e-02\n",
      "   4.15948256e-01  1.61564519e-01  1.38350121e-01 -2.13347358e-01]\n",
      " [ 2.79817777e-01 -5.22719790e-01  7.71433751e-02  4.50140550e-01\n",
      "   6.77943969e-01 -6.34430416e-02  5.71741642e-02  9.86608469e-02\n",
      "  -1.54328954e-01 -2.68695451e-01  1.19488251e-01 -1.06573141e-01\n",
      "  -2.89389416e-02  2.63128007e-02 -9.76595241e-02 -1.26996562e-01\n",
      "   9.94591488e-02  3.89466696e-01  4.76194018e-01  1.09689980e-01]\n",
      " [-1.45680327e-01  2.25589374e-01  2.66592397e-01 -5.62281415e-01\n",
      "  -2.48495074e-02 -2.21075388e-01 -3.05549827e-02  6.45765970e-02\n",
      "  -1.49911166e-01  1.39580580e-01  5.05830063e-02  6.25992175e-02\n",
      "   1.85943588e-01 -3.37744949e-01  4.20562964e-02 -4.08750021e-01\n",
      "   5.85928068e-01 -2.35434142e-01  4.66024493e-02  1.06152371e-01]\n",
      " [ 1.41616291e-02 -1.76471095e-02  2.22225970e-01  4.11684537e-02\n",
      "  -1.40392910e-01 -2.73940565e-02  5.86510080e-02  1.54797866e-01\n",
      "   1.18458587e-01 -4.68195165e-01  1.32358763e-01  1.20236365e-01\n",
      "  -2.04513609e-01  3.58059905e-01  3.55778997e-01 -3.77855630e-01\n",
      "   3.85594995e-02 -8.30728284e-03  3.08705946e-01 -2.18138683e-01]\n",
      " [-7.46569900e-02  2.37815820e-01 -2.30520552e-01  4.26917087e-01\n",
      "  -4.67589809e-01  2.57089247e-01  9.97681918e-02 -1.93523167e-01\n",
      "  -2.62920405e-02 -7.79129929e-02  1.87309131e-02  7.00266245e-02\n",
      "  -1.81810415e-02  6.90734745e-02 -2.20781413e-01  5.55137380e-01\n",
      "  -1.22893013e-01  1.49576241e-01  1.55552934e-01 -2.75624160e-02]\n",
      " [ 2.81253808e-01 -1.62376448e-01 -3.74026617e-02  3.36269093e-01\n",
      "  -3.76627442e-02  8.64035294e-02  4.21189266e-02  9.93785491e-02\n",
      "   2.61350582e-01 -9.87214621e-02  1.66580562e-01  3.23917525e-01\n",
      "  -2.84271464e-01 -1.68490298e-01 -2.84170045e-01  1.22117350e-01\n",
      "  -1.46809248e-01  2.94372100e-01 -9.40073278e-03  3.46177562e-01]]\n"
     ]
    }
   ],
   "source": [
    "print(\"weights between input and first hidden layer:\")\n",
    "print(clf.coefs_[0])\n",
    "print(\"\\nweights between first hidden and second hidden layer:\")\n",
    "print(clf.coefs_[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "w0 =  -0.010801582145105163\n",
      "w1 =  -0.4277173402730053\n"
     ]
    }
   ],
   "source": [
    "print(\"w0 = \", clf.coefs_[0][0][0])\n",
    "print(\"w1 = \", clf.coefs_[0][1][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bias values for first hidden layer:\n",
      "[ 0.29125221 -0.05417281 -0.04460572  0.03278668 -0.21341964  0.42584795\n",
      "  0.30204928  0.52420931 -0.1017441  -0.32788903  0.05885043  0.12268569\n",
      "  0.27527179 -0.20856862  0.23249662  0.04270127  0.24795966  0.22803866\n",
      " -0.44233788  0.72005214 -0.21263452 -0.09889703 -0.08896461 -0.80595093\n",
      "  0.09790973 -0.05138419 -0.1338594  -0.29079161  0.18658516  0.11313906\n",
      " -0.30051842 -0.25197066  0.10721609 -0.00678107  0.48308657 -0.29779301\n",
      " -0.07508983  0.07221026  0.31909223  0.86860387 -0.07558453  0.07670519\n",
      " -0.0008877   0.09432474  0.34035616  0.1007482   0.41467942 -0.14956309\n",
      "  0.08471959 -0.16131774]\n",
      "\n",
      "Bias values for second hidden layer:\n",
      "[-0.18235028  0.09143197  0.298699   -0.00196421  0.16784986  0.00937275\n",
      " -0.46424261 -0.00095167 -0.18392112 -0.02758631 -0.54650475  0.26651379\n",
      "  0.02257654  0.30763668  0.00906427 -0.30144054  0.83521791  0.05459248\n",
      " -0.20762087  0.32028516]\n"
     ]
    }
   ],
   "source": [
    "print(\"Bias values for first hidden layer:\")\n",
    "print(clf.intercepts_[0])\n",
    "print(\"\\nBias values for second hidden layer:\")\n",
    "print(clf.intercepts_[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Second Approach"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 1, loss = 1.45767886\n",
      "Iteration 2, loss = 1.41609300\n",
      "Iteration 3, loss = 1.40821170\n",
      "Iteration 4, loss = 1.40349209\n",
      "Iteration 5, loss = 1.40237822\n",
      "Iteration 6, loss = 1.40181943\n",
      "Iteration 7, loss = 1.39808828\n",
      "Iteration 8, loss = 1.39665743\n",
      "Iteration 9, loss = 1.39658059\n",
      "Iteration 10, loss = 1.39360897\n",
      "Iteration 11, loss = 1.39240045\n",
      "Iteration 12, loss = 1.39216231\n",
      "Iteration 13, loss = 1.39235721\n",
      "Iteration 14, loss = 1.38697160\n",
      "Iteration 15, loss = 1.38864993\n",
      "Iteration 16, loss = 1.38963269\n",
      "Iteration 17, loss = 1.38738679\n",
      "Iteration 18, loss = 1.38444711\n",
      "Iteration 19, loss = 1.38357993\n",
      "Iteration 20, loss = 1.38174196\n",
      "Iteration 21, loss = 1.38213418\n",
      "Iteration 22, loss = 1.38354334\n",
      "Iteration 23, loss = 1.38183143\n",
      "Iteration 24, loss = 1.37913767\n",
      "Iteration 25, loss = 1.37715149\n",
      "Iteration 26, loss = 1.37807733\n",
      "Iteration 27, loss = 1.37643654\n",
      "Iteration 28, loss = 1.37565858\n",
      "Iteration 29, loss = 1.37653251\n",
      "Iteration 30, loss = 1.37399342\n",
      "Iteration 31, loss = 1.37474464\n",
      "Iteration 32, loss = 1.37271774\n",
      "Iteration 33, loss = 1.37433658\n",
      "Iteration 34, loss = 1.37098335\n",
      "Iteration 35, loss = 1.37212334\n",
      "Iteration 36, loss = 1.37089021\n",
      "Iteration 37, loss = 1.37036054\n",
      "Iteration 38, loss = 1.36780644\n",
      "Iteration 39, loss = 1.36823443\n",
      "Iteration 40, loss = 1.36598323\n",
      "Iteration 41, loss = 1.36722528\n",
      "Iteration 42, loss = 1.36759322\n",
      "Iteration 43, loss = 1.36646519\n",
      "Iteration 44, loss = 1.36450841\n",
      "Iteration 45, loss = 1.36694116\n",
      "Iteration 46, loss = 1.36189350\n",
      "Iteration 47, loss = 1.36341813\n",
      "Iteration 48, loss = 1.36540706\n",
      "Iteration 49, loss = 1.36364485\n",
      "Iteration 50, loss = 1.36222082\n",
      "Iteration 51, loss = 1.36152900\n",
      "Iteration 52, loss = 1.36150958\n",
      "Iteration 53, loss = 1.35997507\n",
      "Iteration 54, loss = 1.35936712\n",
      "Iteration 55, loss = 1.36078089\n",
      "Iteration 56, loss = 1.35768213\n",
      "Iteration 57, loss = 1.35621729\n",
      "Iteration 58, loss = 1.35746116\n",
      "Iteration 59, loss = 1.35793685\n",
      "Iteration 60, loss = 1.35456336\n",
      "Iteration 61, loss = 1.35554546\n",
      "Iteration 62, loss = 1.35546316\n",
      "Iteration 63, loss = 1.35427592\n",
      "Iteration 64, loss = 1.35453001\n",
      "Iteration 65, loss = 1.35429654\n",
      "Iteration 66, loss = 1.35450439\n",
      "Iteration 67, loss = 1.35356765\n",
      "Iteration 68, loss = 1.35739684\n",
      "Iteration 69, loss = 1.35300324\n",
      "Iteration 70, loss = 1.35071312\n",
      "Iteration 71, loss = 1.35240206\n",
      "Iteration 72, loss = 1.35017549\n",
      "Iteration 73, loss = 1.34768259\n",
      "Iteration 74, loss = 1.34950686\n",
      "Iteration 75, loss = 1.34851721\n",
      "Iteration 76, loss = 1.35023081\n",
      "Iteration 77, loss = 1.34650030\n",
      "Iteration 78, loss = 1.34769178\n",
      "Iteration 79, loss = 1.34877436\n",
      "Iteration 80, loss = 1.34783987\n",
      "Iteration 81, loss = 1.34585526\n",
      "Iteration 82, loss = 1.34370742\n",
      "Iteration 83, loss = 1.34600055\n",
      "Iteration 84, loss = 1.34315305\n",
      "Iteration 85, loss = 1.34793933\n",
      "Iteration 86, loss = 1.34166683\n",
      "Iteration 87, loss = 1.34485283\n",
      "Iteration 88, loss = 1.34198057\n",
      "Iteration 89, loss = 1.34097401\n",
      "Iteration 90, loss = 1.34100631\n",
      "Iteration 91, loss = 1.34126037\n",
      "Iteration 92, loss = 1.33991407\n",
      "Iteration 93, loss = 1.34260936\n",
      "Iteration 94, loss = 1.34188830\n",
      "Iteration 95, loss = 1.34190022\n",
      "Iteration 96, loss = 1.33873462\n",
      "Iteration 97, loss = 1.33783616\n",
      "Iteration 98, loss = 1.33805813\n",
      "Iteration 99, loss = 1.33966853\n",
      "Iteration 100, loss = 1.33636165\n",
      "Iteration 101, loss = 1.33935916\n",
      "Iteration 102, loss = 1.33770470\n",
      "Iteration 103, loss = 1.33782958\n",
      "Iteration 104, loss = 1.33622852\n",
      "Iteration 105, loss = 1.33173967\n",
      "Iteration 106, loss = 1.33452146\n",
      "Iteration 107, loss = 1.33765210\n",
      "Iteration 108, loss = 1.33379213\n",
      "Iteration 109, loss = 1.33268126\n",
      "Iteration 110, loss = 1.33404250\n",
      "Iteration 111, loss = 1.33316940\n",
      "Iteration 112, loss = 1.33208171\n",
      "Iteration 113, loss = 1.32919855\n",
      "Iteration 114, loss = 1.33121394\n",
      "Iteration 115, loss = 1.32966193\n",
      "Iteration 116, loss = 1.33423969\n",
      "Iteration 117, loss = 1.33112771\n",
      "Iteration 118, loss = 1.32982707\n",
      "Iteration 119, loss = 1.33036888\n",
      "Iteration 120, loss = 1.33075307\n",
      "Iteration 121, loss = 1.33081182\n",
      "Iteration 122, loss = 1.32752079\n",
      "Iteration 123, loss = 1.32727336\n",
      "Iteration 124, loss = 1.32858487\n",
      "Iteration 125, loss = 1.33178291\n",
      "Iteration 126, loss = 1.32789030\n",
      "Iteration 127, loss = 1.32688676\n",
      "Iteration 128, loss = 1.32668013\n",
      "Iteration 129, loss = 1.32548727\n",
      "Iteration 130, loss = 1.32552865\n",
      "Iteration 131, loss = 1.32743083\n",
      "Iteration 132, loss = 1.32660945\n",
      "Iteration 133, loss = 1.32455377\n",
      "Iteration 134, loss = 1.32632803\n",
      "Iteration 135, loss = 1.32431403\n",
      "Iteration 136, loss = 1.32540438\n",
      "Iteration 137, loss = 1.32347094\n",
      "Iteration 138, loss = 1.32209470\n",
      "Iteration 139, loss = 1.32533572\n",
      "Iteration 140, loss = 1.32140292\n",
      "Iteration 141, loss = 1.31993476\n",
      "Iteration 142, loss = 1.32374712\n",
      "Iteration 143, loss = 1.32145026\n",
      "Iteration 144, loss = 1.32189257\n",
      "Iteration 145, loss = 1.32241159\n",
      "Iteration 146, loss = 1.32084677\n",
      "Iteration 147, loss = 1.32018224\n",
      "Iteration 148, loss = 1.31981287\n",
      "Iteration 149, loss = 1.31912184\n",
      "Iteration 150, loss = 1.32042742\n",
      "Iteration 151, loss = 1.31842842\n",
      "Iteration 152, loss = 1.31648739\n",
      "Iteration 153, loss = 1.31756684\n",
      "Iteration 154, loss = 1.31551927\n",
      "Iteration 155, loss = 1.31927712\n",
      "Iteration 156, loss = 1.31493255\n",
      "Iteration 157, loss = 1.31483266\n",
      "Iteration 158, loss = 1.31832990\n",
      "Iteration 159, loss = 1.31600686\n",
      "Iteration 160, loss = 1.31641886\n",
      "Iteration 161, loss = 1.31670726\n",
      "Iteration 162, loss = 1.31530472\n",
      "Iteration 163, loss = 1.31520929\n",
      "Iteration 164, loss = 1.31514661\n",
      "Iteration 165, loss = 1.31485764\n",
      "Iteration 166, loss = 1.31662841\n",
      "Iteration 167, loss = 1.31447168\n",
      "Iteration 168, loss = 1.31740017\n",
      "Iteration 169, loss = 1.31316097\n",
      "Iteration 170, loss = 1.31318813\n",
      "Iteration 171, loss = 1.31213111\n",
      "Iteration 172, loss = 1.31377173\n",
      "Iteration 173, loss = 1.31358278\n",
      "Iteration 174, loss = 1.31690610\n",
      "Iteration 175, loss = 1.31422384\n",
      "Iteration 176, loss = 1.30912897\n",
      "Iteration 177, loss = 1.31256983\n",
      "Iteration 178, loss = 1.31532709\n",
      "Iteration 179, loss = 1.31357056\n",
      "Iteration 180, loss = 1.30895142\n",
      "Iteration 181, loss = 1.30983380\n",
      "Iteration 182, loss = 1.30760271\n",
      "Iteration 183, loss = 1.31161653\n",
      "Iteration 184, loss = 1.30976345\n",
      "Iteration 185, loss = 1.31049810\n",
      "Iteration 186, loss = 1.31369077\n",
      "Iteration 187, loss = 1.30897978\n",
      "Iteration 188, loss = 1.31046959\n",
      "Iteration 189, loss = 1.30785370\n",
      "Iteration 190, loss = 1.30845369\n",
      "Iteration 191, loss = 1.31244743\n",
      "Iteration 192, loss = 1.30708821\n",
      "Iteration 193, loss = 1.30789430\n",
      "Iteration 194, loss = 1.30985405\n",
      "Iteration 195, loss = 1.30899817\n",
      "Iteration 196, loss = 1.30828810\n",
      "Iteration 197, loss = 1.30921513\n",
      "Iteration 198, loss = 1.31174685\n",
      "Iteration 199, loss = 1.31350381\n",
      "Iteration 200, loss = 1.30700651\n",
      "Iteration 201, loss = 1.30456153\n",
      "Iteration 202, loss = 1.30994606\n",
      "Iteration 203, loss = 1.30204322\n",
      "Iteration 204, loss = 1.30307089\n",
      "Iteration 205, loss = 1.30725732\n",
      "Iteration 206, loss = 1.30303390\n",
      "Iteration 207, loss = 1.30541312\n",
      "Iteration 208, loss = 1.30376737\n",
      "Iteration 209, loss = 1.30757406\n",
      "Iteration 210, loss = 1.30537472\n",
      "Iteration 211, loss = 1.30298012\n",
      "Iteration 212, loss = 1.30400117\n",
      "Iteration 213, loss = 1.30267903\n",
      "Iteration 214, loss = 1.30082747\n",
      "Iteration 215, loss = 1.30546759\n",
      "Iteration 216, loss = 1.30278799\n",
      "Iteration 217, loss = 1.30277255\n",
      "Iteration 218, loss = 1.30654023\n",
      "Iteration 219, loss = 1.30240350\n",
      "Iteration 220, loss = 1.30461636\n",
      "Iteration 221, loss = 1.30080252\n",
      "Iteration 222, loss = 1.30183994\n",
      "Iteration 223, loss = 1.30304265\n",
      "Iteration 224, loss = 1.30570829\n",
      "Iteration 225, loss = 1.30013629\n",
      "Iteration 226, loss = 1.30047171\n",
      "Iteration 227, loss = 1.30102360\n",
      "Iteration 228, loss = 1.30131027\n",
      "Iteration 229, loss = 1.29889662\n",
      "Iteration 230, loss = 1.29976156\n",
      "Iteration 231, loss = 1.30096163\n",
      "Iteration 232, loss = 1.30050985\n",
      "Iteration 233, loss = 1.30244164\n",
      "Iteration 234, loss = 1.30334415\n",
      "Iteration 235, loss = 1.30231793\n",
      "Iteration 236, loss = 1.30260167\n",
      "Iteration 237, loss = 1.29933871\n",
      "Iteration 238, loss = 1.30029117\n",
      "Iteration 239, loss = 1.30087859\n",
      "Iteration 240, loss = 1.29812329\n",
      "Iteration 241, loss = 1.29688981\n",
      "Iteration 242, loss = 1.30164305\n",
      "Iteration 243, loss = 1.30391233\n",
      "Iteration 244, loss = 1.30240894\n",
      "Iteration 245, loss = 1.29927683\n",
      "Iteration 246, loss = 1.30466295\n",
      "Iteration 247, loss = 1.29965011\n",
      "Iteration 248, loss = 1.29544204\n",
      "Iteration 249, loss = 1.29970345\n",
      "Iteration 250, loss = 1.29800061\n",
      "Iteration 251, loss = 1.29825950\n",
      "Iteration 252, loss = 1.29778685\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 253, loss = 1.29743085\n",
      "Iteration 254, loss = 1.30525993\n",
      "Iteration 255, loss = 1.29633885\n",
      "Iteration 256, loss = 1.29792738\n",
      "Iteration 257, loss = 1.29797623\n",
      "Iteration 258, loss = 1.29641935\n",
      "Iteration 259, loss = 1.29952870\n",
      "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n",
      "Training set score: 0.433764\n",
      "Test set score: 0.338577\n"
     ]
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "mlp = MLPClassifier(hidden_layer_sizes=(30, 30), max_iter=2000, alpha=1e-4,\n",
    "                    solver='sgd', verbose=10, tol=1e-4, random_state=1,\n",
    "                    learning_rate_init=.1)\n",
    "\n",
    "mlp.fit(X_train, y_train)\n",
    "print(\"Training set score: %f\" % mlp.score(X_train, y_train))\n",
    "print(\"Test set score: %f\" % mlp.score(X_test, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([3, 3, 3, ..., 3, 0, 3])"
      ]
     },
     "execution_count": 172,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictions = mlp.predict(X_test)\n",
    "predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "metadata": {},
   "outputs": [],
   "source": [
    "prob_results = clf.predict_proba(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.24169106, 0.1391937 , 0.2083949 , 0.35850327, 0.05221708],\n",
       "       [0.09507714, 0.16874136, 0.16172881, 0.5611028 , 0.01334989],\n",
       "       [0.07691399, 0.2398949 , 0.20817601, 0.46926019, 0.00575492],\n",
       "       ...,\n",
       "       [0.11633844, 0.09341637, 0.12795963, 0.64285985, 0.01942571],\n",
       "       [0.27560859, 0.27703072, 0.34417345, 0.07483219, 0.02835504],\n",
       "       [0.17155104, 0.23072544, 0.26002705, 0.30412775, 0.03356872]])"
      ]
     },
     "execution_count": 174,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prob_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = mlp.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.24      0.22      0.23       578\n",
      "           1       0.27      0.07      0.11       652\n",
      "           2       0.31      0.44      0.36       804\n",
      "           3       0.43      0.57      0.49       817\n",
      "           4       0.00      0.00      0.00        73\n",
      "\n",
      "    accuracy                           0.34      2924\n",
      "   macro avg       0.25      0.26      0.24      2924\n",
      "weighted avg       0.31      0.34      0.31      2924\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#print(confusion_matrix(y_test, y_pred))\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Manually_check(X,y):\n",
    "    PRED = mlp.predict(X)\n",
    "    LABEL = y\n",
    "    return PRED,y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([2, 3, 2, 1, 2, 0, 3, 2, 0, 3, 2, 0, 2, 0, 3, 1, 2, 3, 2, 0]),\n",
       " array([2, 4, 1, 2, 2, 2, 0, 1, 0, 3, 0, 0, 2, 0, 2, 3, 1, 3, 2, 3]))"
      ]
     },
     "execution_count": 178,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Manually_check(X[0:20],y[0:20])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([4])"
      ]
     },
     "execution_count": 149,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mlp.predict([X[1]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([2])"
      ]
     },
     "execution_count": 150,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mlp.predict([[1, 1, 1, 9, 0, 2, 2, 0, 4, 0, 1, 2, 1, 4, 2, 1, 2, 0]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
