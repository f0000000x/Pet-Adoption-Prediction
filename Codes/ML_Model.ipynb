{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd \n",
    "from numpy import array\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report, confusion_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Type</th>\n",
       "      <th>Breed1</th>\n",
       "      <th>Breed2</th>\n",
       "      <th>Gender</th>\n",
       "      <th>Color1</th>\n",
       "      <th>Color2</th>\n",
       "      <th>Color3</th>\n",
       "      <th>MaturitySize</th>\n",
       "      <th>FurLength</th>\n",
       "      <th>Vaccinated</th>\n",
       "      <th>Dewormed</th>\n",
       "      <th>Sterilized</th>\n",
       "      <th>Health</th>\n",
       "      <th>Quantity</th>\n",
       "      <th>VideoAmt</th>\n",
       "      <th>PhotoAmt</th>\n",
       "      <th>AdoptionSpeed</th>\n",
       "      <th>AgeBins</th>\n",
       "      <th>Pure_breed</th>\n",
       "      <th>Free_or_NeedFee</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>167</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>136</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>175</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>7</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>175</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>8</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>175</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>14987</td>\n",
       "      <td>1</td>\n",
       "      <td>89</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>14988</td>\n",
       "      <td>0</td>\n",
       "      <td>137</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>14989</td>\n",
       "      <td>0</td>\n",
       "      <td>136</td>\n",
       "      <td>100</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>14990</td>\n",
       "      <td>0</td>\n",
       "      <td>136</td>\n",
       "      <td>102</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>14991</td>\n",
       "      <td>0</td>\n",
       "      <td>137</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>14617 rows Ã— 20 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       Type  Breed1  Breed2  Gender  Color1  Color2  Color3  MaturitySize  \\\n",
       "0         0     167       0       1       0       6       0             3   \n",
       "1         0     136       0       1       0       1       0             2   \n",
       "2         1     175       0       1       1       6       0             2   \n",
       "3         1     175       0       0       0       1       0             2   \n",
       "4         1     175       0       1       0       0       0             2   \n",
       "...     ...     ...     ...     ...     ...     ...     ...           ...   \n",
       "14987     1      89       0       0       0       6       0             3   \n",
       "14988     0     137       0       2       0       0       0             2   \n",
       "14989     0     136     100       2       0       3       5             2   \n",
       "14990     0     136     102       2       4       5       5             1   \n",
       "14991     0     137       0       0       3       6       0             3   \n",
       "\n",
       "       FurLength  Vaccinated  Dewormed  Sterilized  Health  Quantity  \\\n",
       "0              2           0         0           0       0         0   \n",
       "1              1           1         1           1       0         0   \n",
       "2              1           2         2           0       0         0   \n",
       "3              2           2         2           0       0         0   \n",
       "4              2           0         0           0       0         0   \n",
       "...          ...         ...       ...         ...     ...       ...   \n",
       "14987          0           2         2           0       0         0   \n",
       "14988          1           0         0           0       0         3   \n",
       "14989          1           2         2           2       0         1   \n",
       "14990          1           0         2           1       0         4   \n",
       "14991          2           2         2           2       0         0   \n",
       "\n",
       "       VideoAmt  PhotoAmt  AdoptionSpeed  AgeBins  Pure_breed  Free_or_NeedFee  \n",
       "0             0         1              2        0           1                1  \n",
       "1             0         2              4        0           1                0  \n",
       "2             0         7              1        0           1                0  \n",
       "3             0         8              2        0           1                1  \n",
       "4             0         3              2        0           1                0  \n",
       "...         ...       ...            ...      ...         ...              ...  \n",
       "14987         0         1              4        1           1                0  \n",
       "14988         0         3              2        0           1                0  \n",
       "14989         0         3              3        4           0                0  \n",
       "14990         0         5              1        0           0                1  \n",
       "14991         0         3              3        1           1                0  \n",
       "\n",
       "[14617 rows x 20 columns]"
      ]
     },
     "execution_count": 123,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.read_csv('/Users/Fox/Desktop/Data Science/Capstone/Codes/EDA-Siqi/EDA.csv', index_col=0)\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame(data) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop Breed1 Breed2\n",
    "#X = df[['Type', 'Gender', 'Color1', 'Color2', 'Color3', 'MaturitySize',\n",
    "#       'FurLength', 'Vaccinated', 'Dewormed', 'Sterilized', 'Health',\n",
    "#       'Quantity', 'VideoAmt', 'PhotoAmt',  'AgeBins',\n",
    "#       'Pure_breed', 'Free_or_NeedFee']].values\n",
    "\n",
    "# Selected Feature\n",
    "X = df[['PhotoAmt','MaturitySize','FurLength','Color1','VideoAmt','Quantity','Dewormed','Sterilized','AgeBins','Vaccinated', 'Gender']].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1, 3, 2, ..., 0, 0, 1],\n",
       "       [2, 2, 1, ..., 0, 1, 1],\n",
       "       [7, 2, 1, ..., 0, 2, 1],\n",
       "       ...,\n",
       "       [3, 2, 1, ..., 4, 2, 2],\n",
       "       [5, 1, 1, ..., 0, 0, 2],\n",
       "       [3, 3, 2, ..., 1, 2, 0]])"
      ]
     },
     "execution_count": 126,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = np.array(df['AdoptionSpeed'].tolist())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SMOTE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original dataset shape Counter({3: 4115, 2: 3923, 1: 3156, 0: 3020, 4: 403})\n"
     ]
    }
   ],
   "source": [
    "from collections import Counter\n",
    "from sklearn.datasets import make_classification\n",
    "from imblearn.over_sampling import SMOTE\n",
    "print('Original dataset shape %s' % Counter(y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Resampled dataset shape Counter({2: 4115, 4: 4115, 1: 4115, 0: 4115, 3: 4115})\n"
     ]
    }
   ],
   "source": [
    "sm = SMOTE(random_state=42)\n",
    "X_res, y_res = sm.fit_resample(X, y)\n",
    "print('Resampled dataset shape %s' % Counter(y_res))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Spliting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X_res, y_res, test_size = 0.30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1, 3, 2, ..., 0, 0, 1],\n",
       "       [2, 2, 1, ..., 0, 1, 1],\n",
       "       [7, 2, 1, ..., 0, 2, 1],\n",
       "       ...,\n",
       "       [3, 2, 1, ..., 4, 2, 2],\n",
       "       [5, 1, 1, ..., 0, 0, 2],\n",
       "       [3, 3, 2, ..., 1, 2, 0]])"
      ]
     },
     "execution_count": 131,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([4, 2, 3, ..., 2, 2, 4])"
      ]
     },
     "execution_count": 132,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SVC(C=1.0, break_ties=False, cache_size=200, class_weight=None, coef0=0.0,\n",
       "    decision_function_shape='ovr', degree=3, gamma='scale', kernel='rbf',\n",
       "    max_iter=-1, probability=False, random_state=None, shrinking=True,\n",
       "    tol=0.001, verbose=False)"
      ]
     },
     "execution_count": 133,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#svclassifier = SVC(kernel='linear')\n",
    "svclassifier = SVC(kernel='rbf') #Gaussian Kernel\n",
    "#svclassifier = SVC(kernel='poly', degree=9) #Polynomial kernel\n",
    "svclassifier.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = svclassifier.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[369 155  56 227 470]\n",
      " [236 255  71 327 310]\n",
      " [283 243  77 296 357]\n",
      " [175 135  49 565 277]\n",
      " [166  61  11 199 803]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.30      0.29      0.29      1277\n",
      "           1       0.30      0.21      0.25      1199\n",
      "           2       0.29      0.06      0.10      1256\n",
      "           3       0.35      0.47      0.40      1201\n",
      "           4       0.36      0.65      0.46      1240\n",
      "\n",
      "    accuracy                           0.34      6173\n",
      "   macro avg       0.32      0.34      0.30      6173\n",
      "weighted avg       0.32      0.34      0.30      6173\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(confusion_matrix(y_test,y_pred))\n",
    "print(classification_report(y_test,y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Manually_check(X,y):\n",
    "    PRED = svclassifier.predict(X)\n",
    "    LABEL = y\n",
    "    return PRED,y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([4, 4, 1, 1, 0]), array([2, 4, 1, 2, 2]))"
      ]
     },
     "execution_count": 137,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Manually_check(X[0:5],y[0:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([2, 2, 1, 0, 0, 0, 1, 1, 2, 1, 0])"
      ]
     },
     "execution_count": 138,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X[9]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## MLP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training set score: 0.403833\n",
      "Test set score: 0.387818\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/Fox/opt/anaconda3/lib/python3.7/site-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.neural_network import MLPClassifier\n",
    "clf = MLPClassifier(solver='sgd', alpha=1e-5,\n",
    "                    hidden_layer_sizes=(500, 200), random_state=1)\n",
    "clf.fit(X_res, y_res)\n",
    "print(\"Training set score: %f\" % clf.score(X_train, y_train))\n",
    "print(\"Test set score: %f\" % clf.score(X_test, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.34      0.36      0.35      1277\n",
      "           1       0.35      0.26      0.30      1199\n",
      "           2       0.32      0.14      0.19      1256\n",
      "           3       0.41      0.44      0.42      1201\n",
      "           4       0.44      0.74      0.55      1240\n",
      "\n",
      "    accuracy                           0.39      6173\n",
      "   macro avg       0.37      0.39      0.36      6173\n",
      "weighted avg       0.37      0.39      0.36      6173\n",
      "\n"
     ]
    }
   ],
   "source": [
    "y_pred = clf.predict(X_test)\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "weights between input and first hidden layer:\n",
      "[[ 0.00891631  0.06626618 -0.09353723 ...  0.05032894  0.11037466\n",
      "  -0.08172269]\n",
      " [-0.10483848 -0.05289907 -0.07276033 ...  0.0417558  -0.06016979\n",
      "   0.0875722 ]\n",
      " [-0.04970676  0.09224272  0.04594831 ...  0.08540063 -0.016392\n",
      "   0.08725682]\n",
      " ...\n",
      " [-0.02039694  0.05276588 -0.02695865 ... -0.04601996 -0.02733221\n",
      "  -0.13229463]\n",
      " [ 0.03273108  0.09943298 -0.04363987 ... -0.03317946  0.16667586\n",
      "  -0.1468383 ]\n",
      " [ 0.02512696  0.04256352 -0.0881324  ...  0.0193815  -0.00487955\n",
      "  -0.09076789]]\n",
      "\n",
      "weights between first hidden and second hidden layer:\n",
      "[[ 0.02913121  0.07984715  0.08335089 ... -0.07245357  0.05464495\n",
      "   0.00737936]\n",
      " [-0.09518543  0.01428728  0.05765084 ...  0.02357128  0.09081826\n",
      "  -0.01985878]\n",
      " [ 0.03440031 -0.01401784 -0.02677123 ... -0.0211325  -0.01241661\n",
      "   0.003111  ]\n",
      " ...\n",
      " [-0.08400045 -0.07249618  0.0619384  ...  0.07563079 -0.04204747\n",
      "  -0.03541815]\n",
      " [-0.05583677  0.08154557  0.00972074 ... -0.03041654  0.03608525\n",
      "  -0.03019924]\n",
      " [ 0.0730487   0.09110641  0.03976894 ...  0.03310991  0.0235381\n",
      "  -0.06711608]]\n"
     ]
    }
   ],
   "source": [
    "print(\"weights between input and first hidden layer:\")\n",
    "print(clf.coefs_[0])\n",
    "print(\"\\nweights between first hidden and second hidden layer:\")\n",
    "print(clf.coefs_[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "w0 =  0.008916309642808514\n",
      "w1 =  -0.10483848163647855\n"
     ]
    }
   ],
   "source": [
    "print(\"w0 = \", clf.coefs_[0][0][0])\n",
    "print(\"w1 = \", clf.coefs_[0][1][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bias values for first hidden layer:\n",
      "[-0.03399329 -0.04345295  0.0495508  -0.03303881  0.01167948 -0.07265374\n",
      "  0.09321166 -0.00621191  0.05318023 -0.07150791  0.0417952  -0.07851507\n",
      " -0.03891577 -0.09207154 -0.0294914   0.01522745  0.06727692  0.10420303\n",
      " -0.01074004 -0.03123066 -0.02437158  0.12570307 -0.07969989 -0.00024183\n",
      "  0.09852929 -0.00924887 -0.01735946  0.0907385   0.1249441   0.10383821\n",
      " -0.03976441  0.04356402 -0.02292436 -0.06449052  0.04608633 -0.03059235\n",
      " -0.0808138  -0.01757793 -0.03642389  0.0879108   0.10162893  0.08939132\n",
      " -0.00879857  0.01745482  0.01973908 -0.1102357   0.15859437  0.04341633\n",
      " -0.05440787  0.13828982  0.00498179 -0.10557717 -0.0660307  -0.10030421\n",
      " -0.03852163 -0.09721671  0.03836401 -0.07169881 -0.02681129 -0.04430081\n",
      "  0.02382329  0.01689531  0.06799671 -0.02217797 -0.05709427  0.13690059\n",
      "  0.00649455 -0.13165053 -0.07486093  0.00796466 -0.02054467 -0.04809954\n",
      " -0.07570221  0.11613378  0.09469218 -0.08655646  0.06495593  0.06128098\n",
      "  0.02482314 -0.09155135  0.07465348  0.06312662  0.07420078  0.0491269\n",
      "  0.06898008 -0.00715198  0.00199247 -0.05918918  0.07855439  0.11330191\n",
      "  0.01960125 -0.00426982  0.17454961 -0.08903494 -0.08311786 -0.02860773\n",
      " -0.12916764  0.02166044  0.13096318  0.0702314   0.02350274  0.08552343\n",
      "  0.08848963 -0.04388129 -0.05004537  0.02867179  0.11882824 -0.13258108\n",
      "  0.09376417 -0.06778024 -0.01592835  0.01808916 -0.0801562   0.00990005\n",
      "  0.00713212  0.05009657  0.02500322 -0.12024781 -0.0643245   0.01060101\n",
      " -0.04251511 -0.00601314  0.14122893 -0.15034524  0.12719639 -0.0044676\n",
      " -0.04359612 -0.02256565  0.08510789 -0.05141432 -0.09446085  0.00983912\n",
      "  0.1034941   0.0255567   0.00284919  0.00482792 -0.05319331  0.03331684\n",
      "  0.12965087  0.01495555 -0.09137793 -0.02512897  0.02882571  0.07060968\n",
      " -0.06469093  0.14490187 -0.02551982  0.04994759  0.11972552 -0.06807835\n",
      "  0.0395936   0.0007961  -0.06189314  0.02053571  0.00463105 -0.02716333\n",
      "  0.02518645  0.09654672  0.1026296   0.08543965  0.08364056 -0.0726995\n",
      " -0.05032082  0.0935786   0.1787196  -0.03491755  0.12472803  0.1096298\n",
      " -0.03335288 -0.05094649  0.08820501 -0.08387464  0.08998046 -0.02549066\n",
      " -0.09042158 -0.09827314 -0.00131363 -0.11767391 -0.07534289  0.04465823\n",
      "  0.09315728  0.08282286 -0.11779705  0.06014185  0.07041986 -0.15400415\n",
      "  0.01421066  0.10092466  0.13768035  0.07677752  0.0102829  -0.0610815\n",
      "  0.02437203  0.02966614  0.06299089 -0.02066323  0.09302118 -0.01730322\n",
      " -0.05379958 -0.11712215 -0.04871859 -0.08864537 -0.10323063  0.11955138\n",
      "  0.053589   -0.07064105  0.04873065  0.00921101  0.00327783 -0.05370759\n",
      " -0.03381192 -0.11390931 -0.05937817  0.03431956 -0.03536961  0.04717242\n",
      "  0.06854053  0.06024935 -0.04976702  0.03275823  0.08941377 -0.02831499\n",
      " -0.05695484  0.07978178  0.00265706  0.04306214 -0.06061068 -0.10802779\n",
      "  0.08140906 -0.09130867  0.00069015  0.056274    0.03264087  0.00145025\n",
      " -0.05276513  0.0350704   0.16269251  0.09274405 -0.10497318  0.01348379\n",
      "  0.18549049 -0.07368646  0.11189144 -0.04659676  0.08033158 -0.07509622\n",
      " -0.01908325 -0.03527079  0.04680067 -0.07675492  0.04144301 -0.12401416\n",
      " -0.03298988 -0.03417834  0.075947    0.0151948  -0.08657934  0.02243913\n",
      "  0.02130313  0.01505186  0.04803402 -0.13397122  0.05730141  0.04661286\n",
      " -0.07344708  0.10101707 -0.01815555  0.1083114   0.0678497   0.01559175\n",
      "  0.04073095  0.045984    0.10993514  0.08891067  0.03310642 -0.12438676\n",
      " -0.10843268 -0.02794415 -0.10304131 -0.03554192 -0.1265617  -0.03532659\n",
      " -0.04156827  0.05682306 -0.08393348 -0.11891239  0.04260542  0.12304935\n",
      "  0.11428479 -0.09603173  0.02017478 -0.01772644 -0.08275304  0.02731789\n",
      "  0.12709146 -0.07997097  0.03415153 -0.10568675 -0.03617577  0.08403692\n",
      " -0.08843976  0.06774764 -0.00799791  0.06144442  0.18901396 -0.00135529\n",
      " -0.01944671 -0.03198309 -0.08887317  0.05680382  0.0514524   0.09901984\n",
      " -0.05842752 -0.06041384  0.1450557   0.01726019  0.03065706 -0.01272987\n",
      "  0.04987152  0.00234104 -0.02007018 -0.03852856 -0.09595019  0.00677475\n",
      " -0.11503157 -0.00840765 -0.11612709  0.11837209 -0.01728591 -0.05708457\n",
      "  0.11656767 -0.09183415  0.02171445 -0.00233785 -0.03295772  0.04142268\n",
      "  0.07883492 -0.0030461   0.01017106  0.09833326 -0.00461652 -0.09193724\n",
      "  0.00748563 -0.03316304  0.07983411  0.01943076 -0.06713314 -0.06827983\n",
      " -0.01764722  0.14838489  0.1110043  -0.03530626 -0.02764974 -0.00237367\n",
      "  0.02518843 -0.08395698 -0.03289433  0.0803131  -0.01189546  0.02315513\n",
      "  0.04940644 -0.0959809   0.08844098 -0.02958483  0.09837564  0.09114236\n",
      "  0.08180615 -0.00086425 -0.0608022   0.02586306  0.1371511   0.07209785\n",
      " -0.07075617  0.10836882 -0.10078785 -0.01530636  0.13811827  0.11398061\n",
      " -0.06599236  0.09719332 -0.12782271  0.01131386 -0.02295786  0.1151776\n",
      " -0.09041637 -0.07304134 -0.00334182 -0.05402645  0.12323583  0.01532249\n",
      "  0.08973685  0.0386519  -0.00117405  0.04526573 -0.17402881  0.0488766\n",
      "  0.15880625 -0.10890045 -0.0109632  -0.08500297  0.01880405 -0.12236421\n",
      "  0.00665741 -0.05342902  0.07261856  0.06715123  0.03541962  0.01060722\n",
      " -0.05408278  0.06896381  0.09767514 -0.03078493 -0.01743107  0.01485095\n",
      "  0.05269854  0.02304424  0.08107944  0.08855307 -0.00729218  0.15776789\n",
      " -0.05834816 -0.05144264  0.03427902 -0.08742439  0.05073579 -0.00623703\n",
      " -0.02126837 -0.03423512 -0.06303056 -0.03975031  0.11721682  0.07487271\n",
      " -0.01904059 -0.0652941  -0.1291099   0.12655921  0.02375488 -0.09241407\n",
      " -0.08815829  0.08864025  0.06269196 -0.05066598 -0.06657108  0.07204368\n",
      " -0.11822012  0.0611044  -0.03249253  0.01247656 -0.07155587 -0.0395257\n",
      " -0.08213977 -0.03751525 -0.09661561  0.02195013  0.02567097 -0.03608568\n",
      "  0.10777817  0.07842716  0.03353119  0.08313228 -0.1206761  -0.00909712\n",
      "  0.08771433 -0.11235022  0.00606511  0.05431779  0.11413154 -0.05340469\n",
      "  0.05226832 -0.02668725 -0.0181513   0.04954427  0.03883363 -0.04650519\n",
      " -0.01185034 -0.06623864  0.05146017 -0.04501243  0.00241881  0.09664583\n",
      "  0.05963861  0.09280468 -0.02378265  0.07694326 -0.1043373   0.12500304\n",
      " -0.00242955  0.05862528  0.10034361  0.09952564  0.0536995   0.05633078\n",
      "  0.11766708 -0.00361286 -0.12319397 -0.08432393  0.13224001 -0.10397697\n",
      "  0.09800769  0.03375583]\n",
      "\n",
      "Bias values for second hidden layer:\n",
      "[-0.05848185  0.06087701  0.05097034  0.05954742  0.08613529 -0.01357153\n",
      " -0.04958496  0.01391976  0.014448    0.04024248  0.0688139  -0.12246617\n",
      "  0.04450892 -0.07408819 -0.00431387  0.06203519 -0.0146873  -0.0524434\n",
      " -0.07581169  0.06394941 -0.05102793 -0.01634147 -0.02519239 -0.02065723\n",
      "  0.00101497  0.05521305  0.03834375 -0.0451399   0.05273243  0.10481046\n",
      "  0.07517305  0.11280285 -0.10175804 -0.06136775  0.10334437  0.05919293\n",
      " -0.04573052 -0.00229508 -0.04824678  0.02298337 -0.05921903 -0.0174157\n",
      "  0.06863881 -0.06178115 -0.09555166  0.05871898  0.01412103  0.03526277\n",
      "  0.01679999 -0.05026803 -0.00800256 -0.0439645  -0.07475084 -0.08283101\n",
      " -0.04353109 -0.05261631  0.05672888 -0.07409767 -0.1065503  -0.05485576\n",
      " -0.10773227  0.09951369 -0.00951719 -0.03421374  0.04504147 -0.00921129\n",
      "  0.01481445 -0.01281606  0.07675427 -0.0676035  -0.03418887 -0.02060741\n",
      " -0.01548561 -0.032165    0.12304368  0.04258529 -0.10260519  0.07305903\n",
      "  0.15816111 -0.07059908 -0.06586826 -0.04838997  0.10527133  0.01516598\n",
      "  0.08627998 -0.07884789  0.02173666 -0.00670064 -0.01488486  0.10140896\n",
      " -0.07867743  0.0597841  -0.01365646 -0.0784041   0.01912104 -0.05582299\n",
      " -0.03384064  0.1559462   0.02831069  0.05658015 -0.0167278   0.09363197\n",
      "  0.04770871 -0.06456361  0.05636382 -0.00813     0.01009524  0.00798501\n",
      "  0.01044487  0.0453406   0.05561185 -0.02491629 -0.01605447  0.05973716\n",
      "  0.07637422 -0.00668555 -0.05579778 -0.04268044 -0.0174885  -0.03469532\n",
      " -0.01068277  0.01850397  0.02664164  0.06710304  0.0976545   0.11200582\n",
      "  0.0405261  -0.08736366 -0.0596463  -0.03643096  0.00119223 -0.06722769\n",
      " -0.07399895 -0.03106742  0.04109298 -0.08159908  0.05635094  0.07310709\n",
      "  0.01271956  0.10037426 -0.02024935  0.00348379  0.09820793 -0.06809514\n",
      "  0.06213425 -0.04167881  0.05164752 -0.0081373   0.05430682  0.25012216\n",
      " -0.05614597  0.05296013  0.04821556  0.07736813  0.06981596 -0.08923602\n",
      " -0.00300213 -0.07330137  0.00107481  0.06263703 -0.06839655  0.07377045\n",
      " -0.0369872   0.01177844 -0.05194621  0.04890721 -0.04048588 -0.09243835\n",
      " -0.07250843 -0.01992344 -0.08554696 -0.07026036 -0.00285467 -0.11079176\n",
      " -0.10545501 -0.0404211   0.09544607  0.0240273   0.05150536  0.0598282\n",
      "  0.04569446  0.01747147 -0.00251349 -0.03578115 -0.1579658   0.16290549\n",
      "  0.05344052  0.02736847 -0.02552044  0.04627396 -0.01303134  0.05286307\n",
      "  0.00757769  0.0871633  -0.0358893   0.07995949 -0.03274582  0.04108783\n",
      "  0.05182094 -0.07452759]\n"
     ]
    }
   ],
   "source": [
    "print(\"Bias values for first hidden layer:\")\n",
    "print(clf.intercepts_[0])\n",
    "print(\"\\nBias values for second hidden layer:\")\n",
    "print(clf.intercepts_[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 1, loss = 1.54787046\n",
      "Iteration 2, loss = 1.55720643\n",
      "Iteration 3, loss = 1.52064286\n",
      "Iteration 4, loss = 1.50117792\n",
      "Iteration 5, loss = 1.51143599\n",
      "Iteration 6, loss = 1.49311631\n",
      "Iteration 7, loss = 1.48535028\n",
      "Iteration 8, loss = 1.48509041\n",
      "Iteration 9, loss = 1.52108092\n",
      "Iteration 10, loss = 1.53010512\n",
      "Iteration 11, loss = 1.48844535\n",
      "Iteration 12, loss = 1.48823449\n",
      "Iteration 13, loss = 1.49133583\n",
      "Iteration 14, loss = 1.46651022\n",
      "Iteration 15, loss = 1.46766692\n",
      "Iteration 16, loss = 1.47896427\n",
      "Iteration 17, loss = 1.46576018\n",
      "Iteration 18, loss = 1.46424887\n",
      "Iteration 19, loss = 1.46944230\n",
      "Iteration 20, loss = 1.46096885\n",
      "Iteration 21, loss = 1.46626906\n",
      "Iteration 22, loss = 1.44752699\n",
      "Iteration 23, loss = 1.50089979\n",
      "Iteration 24, loss = 1.49175066\n",
      "Iteration 25, loss = 1.46555584\n",
      "Iteration 26, loss = 1.45196650\n",
      "Iteration 27, loss = 1.46501381\n",
      "Iteration 28, loss = 1.46702039\n",
      "Iteration 29, loss = 1.43843908\n",
      "Iteration 30, loss = 1.44633294\n",
      "Iteration 31, loss = 1.47439013\n",
      "Iteration 32, loss = 1.45352752\n",
      "Iteration 33, loss = 1.43332846\n",
      "Iteration 34, loss = 1.49180719\n",
      "Iteration 35, loss = 1.47611762\n",
      "Iteration 36, loss = 1.45459953\n",
      "Iteration 37, loss = 1.44116563\n",
      "Iteration 38, loss = 1.44868693\n",
      "Iteration 39, loss = 1.43554116\n",
      "Iteration 40, loss = 1.42713651\n",
      "Iteration 41, loss = 1.51885159\n",
      "Iteration 42, loss = 1.47159906\n",
      "Iteration 43, loss = 1.44424530\n",
      "Iteration 44, loss = 1.46887066\n",
      "Iteration 45, loss = 1.45902184\n",
      "Iteration 46, loss = 1.44143837\n",
      "Iteration 47, loss = 1.43095767\n",
      "Iteration 48, loss = 1.43421826\n",
      "Iteration 49, loss = 1.43069358\n",
      "Iteration 50, loss = 1.41952036\n",
      "Iteration 51, loss = 1.41344824\n",
      "Iteration 52, loss = 1.41916599\n",
      "Iteration 53, loss = 1.42212494\n",
      "Iteration 54, loss = 1.42670561\n",
      "Iteration 55, loss = 1.49195076\n",
      "Iteration 56, loss = 1.44990762\n",
      "Iteration 57, loss = 1.44615466\n",
      "Iteration 58, loss = 1.46161387\n",
      "Iteration 59, loss = 1.43298279\n",
      "Iteration 60, loss = 1.42892830\n",
      "Iteration 61, loss = 1.44624411\n",
      "Iteration 62, loss = 1.41733200\n",
      "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n",
      "Training set score: 0.364463\n",
      "Test set score: 0.328527\n"
     ]
    }
   ],
   "source": [
    "# Second Approach\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "mlp = MLPClassifier(hidden_layer_sizes=(400, 250), max_iter=2000, alpha=1e-4,\n",
    "                    solver='sgd', verbose=10, tol=1e-4, random_state=1,\n",
    "                    learning_rate_init=.1)\n",
    "\n",
    "mlp.fit(X_train, y_train)\n",
    "print(\"Training set score: %f\" % mlp.score(X_train, y_train))\n",
    "print(\"Test set score: %f\" % mlp.score(X_test, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 3, 0, ..., 1, 1, 1])"
      ]
     },
     "execution_count": 118,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictions = mlp.predict(X_test)\n",
    "predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [],
   "source": [
    "prob_results = clf.predict_proba(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.32      0.19      0.24      1236\n",
      "           1       0.25      0.49      0.33      1236\n",
      "           2       0.23      0.08      0.12      1256\n",
      "           3       0.31      0.44      0.36      1203\n",
      "           4       0.60      0.41      0.49      1242\n",
      "\n",
      "    accuracy                           0.32      6173\n",
      "   macro avg       0.34      0.32      0.31      6173\n",
      "weighted avg       0.34      0.32      0.31      6173\n",
      "\n"
     ]
    }
   ],
   "source": [
    "y_pred = mlp.predict(X_test)\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Manually_check(X,y):\n",
    "    PRED = mlp.predict(X)\n",
    "    LABEL = y\n",
    "    return PRED,y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([3, 4, 1, 1, 2, 2, 0, 1, 0, 3, 0, 0, 0, 0, 4, 3, 1, 3, 2, 2]),\n",
       " array([2, 4, 1, 2, 2, 2, 0, 1, 0, 3, 0, 0, 2, 0, 2, 3, 1, 3, 2, 3]))"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Manually_check(X[0:20],y[0:20])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
